{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Cargamos librerías\n",
    "# Librería para representacion de grafos\n",
    "import networkx as nx \n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Librería con modelo GNN y utilidades\n",
    "\n",
    "from utils import *\n",
    "from uci.uci_data import *\n",
    "from models.gnn_model import get_gnn\n",
    "from models.prediction_model import MLPNet\n",
    "from utils.utils import build_optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Definimos una funcion para pasar parametros a las distintas funciones implementadas por los autores\n",
    "\n",
    "class paso_parametros:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# DataSet Housing\n",
    "\n",
    "Este dataset tiene como objetivo determinar el precio de una vivienda en las afueras de Boston. Consta de 13 atributos continuos (tasa de criminalidad, pureza del aire, número de habitaciones de la vivienda....). Datos recopilados por Harrison and Rubinfeld (1978)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Carga datos de dataset Housing\n",
    "uci_path='/notebooks/datasets'\n",
    "df_np = np.loadtxt(uci_path+'/{}/data.txt'.format('housing'))\n",
    "df_y = pd.DataFrame(df_np[:, -1:])\n",
    "df_X = pd.DataFrame(df_np[:, :-1])\n",
    "\n",
    "#Definimos los parámetros del grafo\n",
    "node_mode=0\n",
    "train_edge= 0.7\n",
    "split_sample=0.\n",
    "split_by='y'\n",
    "train_y= 0.7\n",
    "seed=np.random.rand()\n",
    "normalize=True\n",
    "\n",
    "#Generamos el grafo\n",
    "data = get_data(df_X, df_y, node_mode, train_edge, split_sample, \n",
    "                    split_by, train_y, seed,normalize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EGSAGE', 'EGSAGE', 'EGSAGE'] [True, True, True] [64]\n",
      "GNNStack(\n",
      "  (convs): ModuleList(\n",
      "    (0): EGraphSage(\n",
      "      (message_lin): Linear(in_features=14, out_features=64, bias=True)\n",
      "      (agg_lin): Linear(in_features=77, out_features=64, bias=True)\n",
      "      (message_activation): ReLU()\n",
      "      (update_activation): ReLU()\n",
      "    )\n",
      "    (1): EGraphSage(\n",
      "      (message_lin): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (agg_lin): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (message_activation): ReLU()\n",
      "      (update_activation): ReLU()\n",
      "    )\n",
      "    (2): EGraphSage(\n",
      "      (message_lin): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (agg_lin): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (message_activation): ReLU()\n",
      "      (update_activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (node_post_mlp): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (edge_update_mlps): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=129, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Pasamos los distintos parámetros del modelo        \n",
    "parametros_modelo = {\n",
    "    \"model_types\":'EGSAGE_EGSAGE_EGSAGE',\n",
    "    \"norm_embs\":None,\n",
    "    \"post_hiddens\":None,\n",
    "    \"node_dim\": 64,\n",
    "    \"edge_dim\":64,\n",
    "    \"edge_mode\":1,\n",
    "    \"gnn_activation\":'relu',\n",
    "    \"concat_states\":False,\n",
    "    \"dropout\":0.,\n",
    "    \"aggr\":'mean'\n",
    "}    \n",
    "device='cuda'\n",
    "\n",
    "#Generamos el modelo y lo mostramos\n",
    "model = get_gnn(data, paso_parametros(**parametros_modelo)).to(device)\n",
    "\n",
    "# Imprimimos el modelo\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (1): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esta red neuronal asigna valores a los arcos\n",
    "impute_hiddens='64'\n",
    "impute_hiddens = list(map(int,impute_hiddens.split('_')))\n",
    "input_dim = parametros_modelo['node_dim'] * 2\n",
    "output_dim = 1\n",
    "impute_activation='relu'\n",
    "impute_model = MLPNet(input_dim, output_dim,\n",
    "                            hidden_layer_sizes=impute_hiddens,\n",
    "                            hidden_activation=impute_activation,\n",
    "                            dropout=parametros_modelo['dropout']).to(device)\n",
    "impute_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros del modelo GNN\n",
      "-----------\n",
      "convs.0.message_lin.weight torch.Size([64, 14])\n",
      "convs.0.message_lin.bias torch.Size([64])\n",
      "convs.0.agg_lin.weight torch.Size([64, 77])\n",
      "convs.0.agg_lin.bias torch.Size([64])\n",
      "convs.1.message_lin.weight torch.Size([64, 128])\n",
      "convs.1.message_lin.bias torch.Size([64])\n",
      "convs.1.agg_lin.weight torch.Size([64, 128])\n",
      "convs.1.agg_lin.bias torch.Size([64])\n",
      "convs.2.message_lin.weight torch.Size([64, 128])\n",
      "convs.2.message_lin.bias torch.Size([64])\n",
      "convs.2.agg_lin.weight torch.Size([64, 128])\n",
      "convs.2.agg_lin.bias torch.Size([64])\n",
      "node_post_mlp.0.0.weight torch.Size([64, 64])\n",
      "node_post_mlp.0.0.bias torch.Size([64])\n",
      "node_post_mlp.1.weight torch.Size([64, 64])\n",
      "node_post_mlp.1.bias torch.Size([64])\n",
      "edge_update_mlps.0.0.weight torch.Size([64, 129])\n",
      "edge_update_mlps.0.0.bias torch.Size([64])\n",
      "edge_update_mlps.1.0.weight torch.Size([64, 192])\n",
      "edge_update_mlps.1.0.bias torch.Size([64])\n",
      "edge_update_mlps.2.0.weight torch.Size([64, 192])\n",
      "edge_update_mlps.2.0.bias torch.Size([64])\n",
      "+++++++++++\n",
      "Parametros del modelo Impute model\n",
      "-----------\n",
      "layers.0.0.weight torch.Size([64, 128])\n",
      "layers.0.0.bias torch.Size([64])\n",
      "layers.1.0.weight torch.Size([1, 64])\n",
      "layers.1.0.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "#Podemos ver los parametros de los dos modelos.\n",
    "print(\"Parametros del modelo GNN\")\n",
    "print(\"-----------\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name,param.shape)\n",
    "print(\"+++++++++++\")\n",
    "print(\"Parametros del modelo Impute model\")\n",
    "print(\"-----------\")\n",
    "for name, param in impute_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.shape)\n",
    "\n",
    "#Unimos los parametros\n",
    "trainable_parameters = list(model.parameters()) + list(impute_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "epochs=20000\n",
    "known=0.7 #Probabilidad de conocer el valor del atributo del arco (rdrop=1-known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizamos los datos del entrenamiento\n",
    "\n",
    "x = data.x.clone().detach().to(device)\n",
    "all_train_edge_index = data.train_edge_index.clone().detach().to(device)\n",
    "all_train_edge_attr = data.train_edge_attr.clone().detach().to(device)\n",
    "all_train_labels = data.train_labels.clone().detach().to(device)\n",
    "train_edge_index, train_edge_attr, train_labels = all_train_edge_index, \\\n",
    "                                                  all_train_edge_attr, \\\n",
    "                                                  all_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1673, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Loss final:0.0033620730973780155\n"
     ]
    }
   ],
   "source": [
    "########################### NO ejecutar \n",
    "\n",
    "\n",
    "#Parametros del optimizador.\n",
    "parametros_opt = {\n",
    "    \"opt\":'adam',\n",
    "    \"weight_decay\":0.,\n",
    "    \"lr\":0.001,\n",
    "    \"opt_scheduler\":'none',\n",
    "    \"opt_decay_step\":1000,\n",
    "    \"opt_decay_rate\":0.9\n",
    "}    \n",
    "# build optimizer\n",
    "scheduler, opt = build_optimizer(paso_parametros(**parametros_opt), trainable_parameters)\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    impute_model.train()\n",
    "    \n",
    "    # Obtenemos los arcos para los que sabemos el valor de su atributo\n",
    "    known_mask = get_known_mask(known, int(train_edge_attr.shape[0] / 2)).to(device)\n",
    "    double_known_mask = torch.cat((known_mask, known_mask), dim=0)\n",
    "    known_edge_index, known_edge_attr = mask_edge(train_edge_index, train_edge_attr, \n",
    "                                                  double_known_mask, True)\n",
    "    #################\n",
    "    opt.zero_grad()\n",
    "    # Calculamos el embeding del nodo\n",
    "    x_embd = model(x, known_edge_attr, known_edge_index) # Dimensiones 519x64\n",
    "    # Predecimos la etiqueta del arco\n",
    "    pred = impute_model([x_embd[train_edge_index[0]], x_embd[train_edge_index[1]]]) #Dimensiones 9318x1\n",
    "    pred_train = pred[:int(train_edge_attr.shape[0] / 2),0] # Dimensiones 4659\n",
    "    # Comparamos con la etiqueta real del arco\n",
    "    label_train = train_labels\n",
    "    loss = F.mse_loss(pred_train, label_train)\n",
    "    if epoch%500==1:\n",
    "        print(loss)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "print(\"Loss final:{}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Grabamos el modelo #### Dejamos comentado\n",
    "#torch.save(model.state_dict(), uci_path+'housing/saved_models/model')\n",
    "#torch.save(imputete_model.state_dict(), uci_path+'housing/saved_models/imputate_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargado el modelo\n",
    "model.load_state_dict(torch.load(uci_path+'/housing/saved_model/model'))\n",
    "impute_model.load_state_dict(torch.load(uci_path+'/housing/saved_model/impute_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.02083709090948105 RMSE: 0.14435058333613013 MAE: 0.07592562586069107\n"
     ]
    }
   ],
   "source": [
    "#Evaluamos el modelo\n",
    "\n",
    "test_input_edge_index = all_train_edge_index\n",
    "test_input_edge_attr = all_train_edge_attr\n",
    "test_edge_index = data.test_edge_index.clone().detach().to(device)\n",
    "test_edge_attr = data.test_edge_attr.clone().detach().to(device)\n",
    "test_labels = data.test_labels.clone().detach().to(device)\n",
    "\n",
    "model.eval()\n",
    "impute_model.eval()\n",
    "with torch.no_grad():\n",
    "    x_embd = model(x, test_input_edge_attr, test_input_edge_index)\n",
    "    pred = impute_model([x_embd[test_edge_index[0], :], x_embd[test_edge_index[1], :]])\n",
    "    pred_test = pred[:int(test_edge_attr.shape[0] / 2),0]\n",
    "    label_test = test_labels\n",
    "    mse = F.mse_loss(pred_test, label_test)\n",
    "    test_rmse = np.sqrt(mse.item())\n",
    "    l1 = F.l1_loss(pred_test, label_test)\n",
    "    test_l1 = l1.item()\n",
    "print(\"MSE: {} RMSE: {} MAE: {}\".format(mse.item(), test_rmse,test_l1))\n",
    "\n",
    "# Guardamos MAE y RMSE en una lista\n",
    "val_GRAPE=[test_l1, test_rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18000000715255737, 0.2692031264305115, 0.17283950746059418, 0.043478261679410934, 0.5531914830207825]\n",
      "[0.014208436012268066, 0.20125411450862885, 0.1994914412498474, 0.12494659423828125, 0.6382462382316589]\n"
     ]
    }
   ],
   "source": [
    "# Por curiosidad mostramos como serian las 5 primeras etiquetas vs sus prediciones\n",
    "print(label_test[0:5].tolist())\n",
    "print(pred_test[0:5].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Estos valores son buenos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos con otros métodos de imputacion de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Utilizamos los parametros para los que sabemos sus valores\n",
    "train_edge_mask = data.train_edge_mask.numpy()\n",
    "\n",
    "#Obtenemos las matrices de parametros completos e incompletos\n",
    "from utils.utils import construct_missing_X_from_mask\n",
    "X, X_incomplete = construct_missing_X_from_mask(train_edge_mask, data.df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset completo: \n",
      "[0.         0.18       0.06781525 0.         0.31481481]\n",
      "Dataset incompleto: \n",
      "[0.                nan 0.06781525 0.         0.31481481]\n"
     ]
    }
   ],
   "source": [
    "#Vemos un ejemplo con la primera observacion\n",
    "print(\"Dataset completo: \\n{}\".format(X[0][0:5]))\n",
    "print(\"Dataset incompleto: \\n{}\".format(X_incomplete[0][0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Para los distintos métodos de imputacion, los autores utilizan\n",
    "# la libreria \"fancyimpute\" con distintos métodos\n",
    "\n",
    "from fancyimpute import SimpleFill, KNN, IterativeImputer, IterativeSVD, SoftImpute\n",
    "\n",
    "# Función para imputar valores\n",
    "def baseline_inpute(X_incomplete, method='mean',level=0):\n",
    "\n",
    "    if method == 'mean':\n",
    "        X_filled_mean = SimpleFill().fit_transform(X_incomplete)\n",
    "        return X_filled_mean\n",
    "    elif method == 'knn':\n",
    "        k = [3,10,50][level]\n",
    "        X_filled_knn = KNN(k=k, verbose=False).fit_transform(X_incomplete)\n",
    "        return X_filled_knn\n",
    "    elif method == 'svd':\n",
    "        rank = [np.ceil((X_incomplete.shape[1]-1)/10),np.ceil((X_incomplete.shape[1]-1)/5),X_incomplete.shape[1]-1][level]\n",
    "        X_filled_svd = IterativeSVD(rank=int(rank),verbose=False).fit_transform(X_incomplete)\n",
    "        return X_filled_svd\n",
    "    elif method == 'mice':\n",
    "        max_iter = [3,10,50][level]\n",
    "        X_filled_mice = IterativeImputer(max_iter=max_iter).fit_transform(X_incomplete)\n",
    "        return X_filled_mice\n",
    "    elif method == 'spectral':\n",
    "        # default value for the sparsity level is with respect to the maximum singular value,\n",
    "        # this is now done in a heuristic way\n",
    "        sparsity = [0.5,None,3][level]\n",
    "        X_filled_spectral = SoftImpute(shrinkage_value=sparsity).fit_transform(X_incomplete)\n",
    "        return X_filled_spectral\n",
    "    else:\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Como primer ejemplo, usamos la media para imputar los valores.\n",
    "method='mean'\n",
    "level=0\n",
    "X_filled = baseline_inpute(X_incomplete, method,level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset completo: \n",
      "[0.         0.18       0.06781525 0.         0.31481481 0.57750527]\n",
      "Dataset incompleto: \n",
      "[0.                nan 0.06781525 0.         0.31481481 0.57750527]\n",
      "Dataset relleno: \n",
      "[0.         0.12005556 0.06781525 0.         0.31481481 0.57750527]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset completo: \\n{}\".format(X[0][0:6]))\n",
    "print(\"Dataset incompleto: \\n{}\".format(X_incomplete[0][0:6]))\n",
    "print(\"Dataset relleno: \\n{}\".format(X_filled[0][0:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "mask = np.isnan(X_incomplete)\n",
    "diff = X[mask] - X_filled[mask]\n",
    "mae = np.mean(np.abs(diff))\n",
    "rmse = np.sqrt(np.mean(diff**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1809402097519347 0.242065033692623\n"
     ]
    }
   ],
   "source": [
    "print(mae, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos para todos los métodos tratados en el articulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Max Singular Value of X_init = 27.654676\n",
      "[SoftImpute] Iter 1: observed MAE=0.018642 rank=13\n",
      "[SoftImpute] Iter 2: observed MAE=0.018779 rank=13\n",
      "[SoftImpute] Iter 3: observed MAE=0.018902 rank=13\n",
      "[SoftImpute] Iter 4: observed MAE=0.019017 rank=13\n",
      "[SoftImpute] Iter 5: observed MAE=0.019125 rank=13\n",
      "[SoftImpute] Iter 6: observed MAE=0.019232 rank=13\n",
      "[SoftImpute] Iter 7: observed MAE=0.019335 rank=13\n",
      "[SoftImpute] Iter 8: observed MAE=0.019434 rank=13\n",
      "[SoftImpute] Iter 9: observed MAE=0.019530 rank=13\n",
      "[SoftImpute] Iter 10: observed MAE=0.019620 rank=13\n",
      "[SoftImpute] Iter 11: observed MAE=0.019705 rank=13\n",
      "[SoftImpute] Iter 12: observed MAE=0.019787 rank=13\n",
      "[SoftImpute] Iter 13: observed MAE=0.019866 rank=13\n",
      "[SoftImpute] Iter 14: observed MAE=0.019940 rank=13\n",
      "[SoftImpute] Iter 15: observed MAE=0.020011 rank=13\n",
      "[SoftImpute] Iter 16: observed MAE=0.020079 rank=13\n",
      "[SoftImpute] Iter 17: observed MAE=0.020142 rank=13\n",
      "[SoftImpute] Iter 18: observed MAE=0.020200 rank=13\n",
      "[SoftImpute] Iter 19: observed MAE=0.020253 rank=13\n",
      "[SoftImpute] Iter 20: observed MAE=0.020302 rank=13\n",
      "[SoftImpute] Iter 21: observed MAE=0.020346 rank=13\n",
      "[SoftImpute] Iter 22: observed MAE=0.020387 rank=13\n",
      "[SoftImpute] Iter 23: observed MAE=0.020425 rank=13\n",
      "[SoftImpute] Iter 24: observed MAE=0.020461 rank=13\n",
      "[SoftImpute] Iter 25: observed MAE=0.020495 rank=13\n",
      "[SoftImpute] Iter 26: observed MAE=0.020525 rank=13\n",
      "[SoftImpute] Iter 27: observed MAE=0.020552 rank=13\n",
      "[SoftImpute] Iter 28: observed MAE=0.020577 rank=13\n",
      "[SoftImpute] Iter 29: observed MAE=0.020600 rank=13\n",
      "[SoftImpute] Iter 30: observed MAE=0.020619 rank=13\n",
      "[SoftImpute] Iter 31: observed MAE=0.020636 rank=13\n",
      "[SoftImpute] Iter 32: observed MAE=0.020652 rank=13\n",
      "[SoftImpute] Iter 33: observed MAE=0.020665 rank=13\n",
      "[SoftImpute] Iter 34: observed MAE=0.020677 rank=13\n",
      "[SoftImpute] Iter 35: observed MAE=0.020689 rank=13\n",
      "[SoftImpute] Iter 36: observed MAE=0.020698 rank=13\n",
      "[SoftImpute] Iter 37: observed MAE=0.020708 rank=13\n",
      "[SoftImpute] Iter 38: observed MAE=0.020715 rank=13\n",
      "[SoftImpute] Iter 39: observed MAE=0.020722 rank=13\n",
      "[SoftImpute] Iter 40: observed MAE=0.020727 rank=13\n",
      "[SoftImpute] Iter 41: observed MAE=0.020732 rank=13\n",
      "[SoftImpute] Iter 42: observed MAE=0.020735 rank=13\n",
      "[SoftImpute] Iter 43: observed MAE=0.020739 rank=13\n",
      "[SoftImpute] Iter 44: observed MAE=0.020741 rank=13\n",
      "[SoftImpute] Iter 45: observed MAE=0.020744 rank=13\n",
      "[SoftImpute] Iter 46: observed MAE=0.020745 rank=13\n",
      "[SoftImpute] Iter 47: observed MAE=0.020747 rank=13\n",
      "[SoftImpute] Iter 48: observed MAE=0.020748 rank=13\n",
      "[SoftImpute] Iter 49: observed MAE=0.020749 rank=13\n",
      "[SoftImpute] Iter 50: observed MAE=0.020750 rank=13\n",
      "[SoftImpute] Iter 51: observed MAE=0.020751 rank=13\n",
      "[SoftImpute] Iter 52: observed MAE=0.020751 rank=13\n",
      "[SoftImpute] Iter 53: observed MAE=0.020752 rank=13\n",
      "[SoftImpute] Iter 54: observed MAE=0.020752 rank=13\n",
      "[SoftImpute] Iter 55: observed MAE=0.020752 rank=13\n",
      "[SoftImpute] Iter 56: observed MAE=0.020752 rank=13\n",
      "[SoftImpute] Iter 57: observed MAE=0.020752 rank=13\n",
      "[SoftImpute] Iter 58: observed MAE=0.020752 rank=13\n",
      "[SoftImpute] Iter 59: observed MAE=0.020751 rank=13\n",
      "[SoftImpute] Iter 60: observed MAE=0.020751 rank=13\n",
      "[SoftImpute] Iter 61: observed MAE=0.020751 rank=13\n",
      "[SoftImpute] Iter 62: observed MAE=0.020751 rank=13\n",
      "[SoftImpute] Iter 63: observed MAE=0.020750 rank=13\n",
      "[SoftImpute] Iter 64: observed MAE=0.020750 rank=13\n",
      "[SoftImpute] Iter 65: observed MAE=0.020750 rank=13\n",
      "[SoftImpute] Iter 66: observed MAE=0.020750 rank=13\n",
      "[SoftImpute] Iter 67: observed MAE=0.020749 rank=13\n",
      "[SoftImpute] Iter 68: observed MAE=0.020749 rank=13\n",
      "[SoftImpute] Iter 69: observed MAE=0.020749 rank=13\n",
      "[SoftImpute] Iter 70: observed MAE=0.020748 rank=13\n",
      "[SoftImpute] Iter 71: observed MAE=0.020748 rank=13\n",
      "[SoftImpute] Iter 72: observed MAE=0.020748 rank=13\n",
      "[SoftImpute] Iter 73: observed MAE=0.020747 rank=13\n",
      "[SoftImpute] Iter 74: observed MAE=0.020747 rank=13\n",
      "[SoftImpute] Iter 75: observed MAE=0.020747 rank=13\n",
      "[SoftImpute] Iter 76: observed MAE=0.020747 rank=13\n",
      "[SoftImpute] Iter 77: observed MAE=0.020746 rank=13\n",
      "[SoftImpute] Stopped after iteration 77 for lambda=0.553094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "best_levels = {'mean':0, 'knn':2, 'mice':0, 'svd':2, 'spectral':1}\n",
    "\n",
    "# Probamos todos los métodos y los guardamos en una lista\n",
    "val_baseline=[]\n",
    "for method in ['mean', 'knn', 'mice', 'svd', 'spectral']:\n",
    "    level = best_levels[method]\n",
    "    #print(\"using best level {} for {}\".format(level,method))\n",
    "    X_filled = baseline_inpute(X_incomplete, method,level)\n",
    "    mask = np.isnan(X_incomplete)\n",
    "    diff = X[mask] - X_filled[mask]\n",
    "    mae = np.mean(np.abs(diff))\n",
    "    rmse = np.sqrt(np.mean(diff**2))\n",
    "    val_baseline.append([mae, rmse])\n",
    "#Añadimos el valor de la GNN\n",
    "val_baseline.append(val_GRAPE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.180940</td>\n",
       "      <td>0.242065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.095524</td>\n",
       "      <td>0.170916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svd</th>\n",
       "      <td>0.115458</td>\n",
       "      <td>0.171414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mice</th>\n",
       "      <td>0.141847</td>\n",
       "      <td>0.201412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectral</th>\n",
       "      <td>0.136550</td>\n",
       "      <td>0.198483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grape</th>\n",
       "      <td>0.075926</td>\n",
       "      <td>0.144351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mae      rmse\n",
       "mean      0.180940  0.242065\n",
       "knn       0.095524  0.170916\n",
       "svd       0.115458  0.171414\n",
       "mice      0.141847  0.201412\n",
       "spectral  0.136550  0.198483\n",
       "grape     0.075926  0.144351"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=pd.DataFrame(val_baseline, columns=['mae','rmse'], index=['mean', 'knn', 'svd', 'mice', 'spectral','grape'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normalizamos mae y representamos\n",
    "import seaborn as sns\n",
    "df2=df\n",
    "df2['mae']=df['mae']/df['mae']['mean']\n",
    "\n",
    "g=sns.catplot(kind=\"bar\", data=df2.T[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecimos Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EGSAGE', 'EGSAGE'] [True, True] [16]\n",
      "GNNStack(\n",
      "  (convs): ModuleList(\n",
      "    (0): EGraphSage(\n",
      "      (message_lin): Linear(in_features=14, out_features=16, bias=True)\n",
      "      (agg_lin): Linear(in_features=29, out_features=16, bias=True)\n",
      "      (message_activation): ReLU()\n",
      "      (update_activation): ReLU()\n",
      "    )\n",
      "    (1): EGraphSage(\n",
      "      (message_lin): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (agg_lin): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (message_activation): ReLU()\n",
      "      (update_activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (node_post_mlp): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
      "  )\n",
      "  (edge_update_mlps): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=33, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=48, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MLPNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=1, bias=True)\n",
      "      (1): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MLPNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=13, out_features=1, bias=True)\n",
      "      (1): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Pasamos los distintos parámetros del modelo        \n",
    "parametros_modelo = {\n",
    "    \"model_types\":'EGSAGE_EGSAGE',\n",
    "    \"norm_embs\":None,\n",
    "    \"post_hiddens\":None,\n",
    "    \"node_dim\": 16,\n",
    "    \"edge_dim\":16,\n",
    "    \"edge_mode\":1,\n",
    "    \"gnn_activation\":'relu',\n",
    "    \"concat_states\":False,\n",
    "    \"dropout\":0.,\n",
    "    \"aggr\":'mean'\n",
    "}    \n",
    "device='cuda'\n",
    "\n",
    "#Generamos el modelo y lo mostramos\n",
    "model_y = get_gnn(data, paso_parametros(**parametros_modelo)).to(device)\n",
    "\n",
    "# Imprimimos el modelo\n",
    "print(model_y)\n",
    "\n",
    "# Esta red neuronal asigna valores a los arcos\n",
    "impute_hiddens=''\n",
    "input_dim = parametros_modelo['node_dim'] * 2\n",
    "output_dim = 1\n",
    "impute_activation='relu'\n",
    "impute_model_y = MLPNet(input_dim, output_dim,\n",
    "                            hidden_layer_sizes=impute_hiddens,\n",
    "                            hidden_activation=impute_activation,\n",
    "                            dropout=parametros_modelo['dropout']).to(device)\n",
    "print(impute_model_y)\n",
    "\n",
    "\n",
    "# Esta red neuronal asigna valores de 'y'\n",
    "n_row, n_col = data.df_X.shape\n",
    "predict_hiddens = []\n",
    "predict_model = MLPNet(n_col, 1,\n",
    "                           hidden_layer_sizes=predict_hiddens,\n",
    "                           dropout=parametros_modelo['dropout']).to(device)\n",
    "\n",
    "print(predict_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Parametros a entrenar\n",
    "trainable_parameters = list(model_y.parameters()) \\\n",
    "                           + list(impute_model_y.parameters()) \\\n",
    "                           + list(predict_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "epochs=20000\n",
    "known=0.7 #Probabilidad de conocer el valor del atributo del arco (rdrop=1-known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all y num is 506, train num is 346, test num is 160\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos del modelo\n",
    "x = data.x.clone().detach().to(device)\n",
    "y = data.y.clone().detach().to(device)\n",
    "edge_index = data.edge_index.clone().detach().to(device)\n",
    "train_edge_index = data.train_edge_index.clone().detach().to(device)\n",
    "train_edge_attr = data.train_edge_attr.clone().detach().to(device)\n",
    "\n",
    "train_y_mask = data.train_y_mask.clone().detach().to(device)\n",
    "test_y_mask = data.test_y_mask.clone().detach().to(device)\n",
    "print(\"all y num is {}, train num is {}, test num is {}\"\\\n",
    "                .format(\n",
    "                train_y_mask.shape[0],torch.sum(train_y_mask),\n",
    "                torch.sum(test_y_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(604.7289, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(44.4409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(38.2700, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(31.2905, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(32.7486, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(26.7865, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(30.1348, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(25.5298, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(23.7596, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(27.6168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(27.2817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(23.2728, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(24.7220, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(25.5683, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(26.5499, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(29.2423, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(25.2146, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(26.2483, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(26.8889, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(21.4974, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(22.8999, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(24.1333, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(25.3495, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(21.5697, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(19.3869, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(21.9836, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(25.1635, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(24.3537, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(26.8662, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(24.5669, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(20.7867, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(29.9583, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(22.3704, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(27.8210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(25.1238, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(23.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(21.1407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(26.8124, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(23.5864, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(21.2634, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Parametros del optimizador.\n",
    "parametros_opt = {\n",
    "    \"opt\":'adam',\n",
    "    \"weight_decay\":0.,\n",
    "    \"lr\":0.001,\n",
    "    \"opt_scheduler\":'none',\n",
    "    \"opt_decay_step\":1000,\n",
    "    \"opt_decay_rate\":0.9\n",
    "} \n",
    "\n",
    "\n",
    "# build optimizer\n",
    "scheduler, opt = build_optimizer(paso_parametros(**parametros_opt), trainable_parameters)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_y.train()\n",
    "    impute_model_y.train()\n",
    "    predict_model.train()\n",
    "\n",
    "    known_mask = get_known_mask(known, int(train_edge_attr.shape[0] / 2)).to(device)\n",
    "    double_known_mask = torch.cat((known_mask, known_mask), dim=0)\n",
    "    known_edge_index, known_edge_attr = mask_edge(train_edge_index, train_edge_attr, double_known_mask, True)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    x_embd = model_y(x, known_edge_attr, known_edge_index)\n",
    "    X = impute_model_y([x_embd[edge_index[0, :int(n_row * n_col)]], x_embd[edge_index[1, :int(n_row * n_col)]]])\n",
    "    X = torch.reshape(X, [n_row, n_col])\n",
    "    pred = predict_model(X)[:, 0]\n",
    "    pred_train = pred[train_y_mask]\n",
    "    label_train = y[train_y_mask]\n",
    "\n",
    "    loss = F.mse_loss(pred_train, label_train)\n",
    "    if epoch%500==1:\n",
    "        print(loss)\n",
    "    loss.backward()\n",
    "    opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Grabamos el modelo #### Dejamos comentado\n",
    "torch.save(model.state_dict(), uci_path+'/housing/saved_model/y_model.pt')\n",
    "torch.save(impute_model.state_dict(), uci_path+'/housing/saved_model/y_impute_model.pt')\n",
    "torch.save(predict_model.state_dict(), uci_path+'/housing/saved_model/y_predict_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargamos el modelo\n",
    "model.load_state_dict(torch.load(uci_path+'/housing/saved_model/y_model.pt'))\n",
    "impute_model.load_state_dict(torch.load(uci_path+'/housing/saved_model/y_impute_model.pt'))\n",
    "predict_model.load_state_dict(torch.load(uci_path+'/housing/saved_model/y_predict_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "model_y.eval()\n",
    "impute_model_y.eval()\n",
    "predict_model.eval()\n",
    "with torch.no_grad():\n",
    "    x_embd = model_y(x, train_edge_attr, train_edge_index)\n",
    "    X = impute_model_y([x_embd[edge_index[0, :int(n_row * n_col)]], x_embd[edge_index[1, :int(n_row * n_col)]]])\n",
    "    X = torch.reshape(X, [n_row, n_col])\n",
    "    pred = predict_model(X)[:, 0]\n",
    "    pred_test = pred[test_y_mask]\n",
    "    label_test = y[test_y_mask]\n",
    "    mse = F.mse_loss(pred_test, label_test)\n",
    "    test_rmse = np.sqrt(mse.item())\n",
    "    l1 = F.l1_loss(pred_test, label_test)\n",
    "    test_l1 = l1.item()\n",
    "\n",
    "val_GRAPE_y=[test_l1, test_rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 19.854755401611328 RMSE: 4.455867525141578 MAE: 2.893282413482666\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: {} RMSE: {} MAE: {}\".format(mse.item(), test_rmse,test_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.600000381469727, 15.0, 18.899999618530273, 21.700000762939453, 19.899999618530273]\n",
      "[23.55421257019043, 21.385515213012695, 20.781034469604492, 21.117944717407227, 19.93079376220703]\n"
     ]
    }
   ],
   "source": [
    "# Vemos las primeras etiquetas real vs previstas\n",
    "print(y[test_y_mask][0:5].tolist())\n",
    "print(pred[test_y_mask][0:5].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {}
   },
   "source": [
    "# ¿Qué obtenemos con los otros metodos de imputacion? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Max Singular Value of X_init = 27.654676\n",
      "[SoftImpute] Iter 1: observed MAE=0.018642 rank=13\n",
      "[SoftImpute] Iter 2: observed MAE=0.018779 rank=13\n",
      "[SoftImpute] Iter 3: observed MAE=0.018902 rank=13\n",
      "[SoftImpute] Iter 4: observed MAE=0.019017 rank=13\n",
      "[SoftImpute] Iter 5: observed MAE=0.019125 rank=13\n",
      "[SoftImpute] Iter 6: observed MAE=0.019232 rank=13\n",
      "[SoftImpute] Iter 7: observed MAE=0.019335 rank=13\n",
      "[SoftImpute] Iter 8: observed MAE=0.019434 rank=13\n",
      "[SoftImpute] Iter 9: observed MAE=0.019530 rank=13\n",
      "[SoftImpute] Iter 10: observed MAE=0.019620 rank=13\n",
      "[SoftImpute] Iter 11: observed MAE=0.019705 rank=13\n",
      "[SoftImpute] Iter 12: observed MAE=0.019787 rank=13\n",
      "[SoftImpute] Iter 13: observed MAE=0.019866 rank=13\n",
      "[SoftImpute] Iter 14: observed MAE=0.019940 rank=13\n",
      "[SoftImpute] Iter 15: observed MAE=0.020011 rank=13\n",
      "[SoftImpute] Iter 16: observed MAE=0.020079 rank=13\n",
      "[SoftImpute] Iter 17: observed MAE=0.020142 rank=13\n",
      "[SoftImpute] Iter 18: observed MAE=0.020200 rank=13\n",
      "[SoftImpute] Iter 19: observed MAE=0.020253 rank=13\n",
      "[SoftImpute] Iter 20: observed MAE=0.020302 rank=13\n",
      "[SoftImpute] Iter 21: observed MAE=0.020346 rank=13\n",
      "[SoftImpute] Iter 22: observed MAE=0.020387 rank=13\n",
      "[SoftImpute] Iter 23: observed MAE=0.020425 rank=13\n",
      "[SoftImpute] Iter 24: observed MAE=0.020461 rank=13\n",
      "[SoftImpute] Iter 25: observed MAE=0.020495 rank=13\n",
      "[SoftImpute] Iter 26: observed MAE=0.020525 rank=13\n",
      "[SoftImpute] Iter 27: observed MAE=0.020552 rank=13\n",
      "[SoftImpute] Iter 28: observed MAE=0.020577 rank=13\n",
      "[SoftImpute] Iter 29: observed MAE=0.020600 rank=13\n",
      "[SoftImpute] Iter 30: observed MAE=0.020619 rank=13\n",
      "[SoftImpute] Iter 31: observed MAE=0.020636 rank=13\n",
      "[SoftImpute] Iter 32: observed MAE=0.020652 rank=13\n",
      "[SoftImpute] Iter 33: observed MAE=0.020665 rank=13\n",
      "[SoftImpute] Iter 34: observed MAE=0.020677 rank=13\n",
      "[SoftImpute] Iter 35: observed MAE=0.020689 rank=13\n",
      "[SoftImpute] Iter 36: observed MAE=0.020698 rank=13\n",
      "[SoftImpute] Iter 37: observed MAE=0.020708 rank=13\n",
      "[SoftImpute] Iter 38: observed MAE=0.020715 rank=13\n",
      "[SoftImpute] Iter 39: observed MAE=0.020722 rank=13\n",
      "[SoftImpute] Iter 40: observed MAE=0.020727 rank=13\n",
      "[SoftImpute] Iter 41: observed MAE=0.020732 rank=13\n",
      "[SoftImpute] Iter 42: observed MAE=0.020735 rank=13\n",
      "[SoftImpute] Iter 43: observed MAE=0.020739 rank=13\n",
      "[SoftImpute] Iter 44: observed MAE=0.020741 rank=13\n",
      "[SoftImpute] Iter 45: observed MAE=0.020744 rank=13\n",
      "[SoftImpute] Iter 46: observed MAE=0.020745 rank=13\n",
      "[SoftImpute] Iter 47: observed MAE=0.020747 rank=13\n",
      "[SoftImpute] Iter 48: observed MAE=0.020748 rank=13\n",
      "[SoftImpute] Iter 49: observed MAE=0.020749 rank=13\n",
      "[SoftImpute] Iter 50: observed MAE=0.020750 rank=13\n",
      "[SoftImpute] Iter 51: observed MAE=0.020751 rank=13\n",
      "[SoftImpute] Iter 52: observed MAE=0.020751 rank=13\n",
      "[SoftImpute] Iter 53: observed MAE=0.020752 rank=13\n",
      "[SoftImpute] Iter 54: observed MAE=0.020752 rank=13\n",
      "[SoftImpute] Iter 55: observed MAE=0.020752 rank=13\n",
      "[SoftImpute] Iter 56: observed MAE=0.020752 rank=13\n",
      "[SoftImpute] Iter 57: observed MAE=0.020752 rank=13\n",
      "[SoftImpute] Iter 58: observed MAE=0.020752 rank=13\n",
      "[SoftImpute] Iter 59: observed MAE=0.020751 rank=13\n",
      "[SoftImpute] Iter 60: observed MAE=0.020751 rank=13\n",
      "[SoftImpute] Iter 61: observed MAE=0.020751 rank=13\n",
      "[SoftImpute] Iter 62: observed MAE=0.020751 rank=13\n",
      "[SoftImpute] Iter 63: observed MAE=0.020750 rank=13\n",
      "[SoftImpute] Iter 64: observed MAE=0.020750 rank=13\n",
      "[SoftImpute] Iter 65: observed MAE=0.020750 rank=13\n",
      "[SoftImpute] Iter 66: observed MAE=0.020750 rank=13\n",
      "[SoftImpute] Iter 67: observed MAE=0.020749 rank=13\n",
      "[SoftImpute] Iter 68: observed MAE=0.020749 rank=13\n",
      "[SoftImpute] Iter 69: observed MAE=0.020749 rank=13\n",
      "[SoftImpute] Iter 70: observed MAE=0.020748 rank=13\n",
      "[SoftImpute] Iter 71: observed MAE=0.020748 rank=13\n",
      "[SoftImpute] Iter 72: observed MAE=0.020748 rank=13\n",
      "[SoftImpute] Iter 73: observed MAE=0.020747 rank=13\n",
      "[SoftImpute] Iter 74: observed MAE=0.020747 rank=13\n",
      "[SoftImpute] Iter 75: observed MAE=0.020747 rank=13\n",
      "[SoftImpute] Iter 76: observed MAE=0.020747 rank=13\n",
      "[SoftImpute] Iter 77: observed MAE=0.020746 rank=13\n",
      "[SoftImpute] Stopped after iteration 77 for lambda=0.553094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "y = data.y.detach().numpy()\n",
    "train_y_mask = data.train_y_mask.clone().detach()\n",
    "test_y_mask = data.test_y_mask.clone().detach()\n",
    "y_train = y[train_y_mask]\n",
    "y_test = y[test_y_mask]\n",
    "\n",
    "\n",
    "val_baseline_y=[]\n",
    "for method in ['mean', 'knn', 'mice', 'svd', 'spectral']:\n",
    "    level = best_levels[method]\n",
    "    #print(\"using best level {} for {}\".format(level,method))\n",
    "    X_filled = baseline_inpute(X_incomplete, method,level)\n",
    "    reg = LinearRegression().fit(X_filled[train_y_mask, :], y_train)\n",
    "    y_pred_test = reg.predict(X_filled[test_y_mask, :])\n",
    "    rmse = np.sqrt(np.mean((y_pred_test - y_test) ** 2))\n",
    "    mae = np.mean(np.abs(y_pred_test - y_test))\n",
    "    val_baseline_y.append([mae, rmse])\n",
    "\n",
    "# Añadimos los valores de grape\n",
    "val_baseline_y.append(val_GRAPE_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.145253</td>\n",
       "      <td>5.913895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>3.969952</td>\n",
       "      <td>5.416851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svd</th>\n",
       "      <td>3.823518</td>\n",
       "      <td>5.505836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mice</th>\n",
       "      <td>4.162773</td>\n",
       "      <td>5.830273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectral</th>\n",
       "      <td>4.091198</td>\n",
       "      <td>5.780162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grape</th>\n",
       "      <td>2.893282</td>\n",
       "      <td>4.455868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mae      rmse\n",
       "mean      4.145253  5.913895\n",
       "knn       3.969952  5.416851\n",
       "svd       3.823518  5.505836\n",
       "mice      4.162773  5.830273\n",
       "spectral  4.091198  5.780162\n",
       "grape     2.893282  4.455868"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(val_baseline_y, columns=['mae','rmse'], index=['mean', 'knn', 'svd', 'mice', 'spectral','grape'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2=df\n",
    "df2['mae']=df['mae']/df['mae']['mean']\n",
    "\n",
    "g=sns.catplot(kind=\"bar\", data=df2.T[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tooooooooooma!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
