{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendiendo el modelo GRAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo está basado en GraphSage. La idea de este notebook es analizar la implementación de GRAPE.\n",
    "\n",
    "<img src=\"notebook_figs/nb1.5_fig001.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar vemos la implementacion del modelo. Se usa la libreria **Pytorch Geometric**.\n",
    "En esta libreria se define la clase *MessagePassing* que permite implementar facilmente un esquema de paso de mensajes de la forma:\n",
    "\n",
    "$$\\mathbf{x}_i^{(k)} = \\gamma^{(k)} \\left( \\mathbf{x}_i^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{j,i}\\right) \\right)$$\n",
    "\n",
    "Lo único que tendremos que definir es:\n",
    "\n",
    "- Un esquema de AGREGACIÓN ($\\square_{j \\in \\mathcal{N}(i)}$) : Puede ser una función diferenciable, e invariante a la permitación, ej., sum, mean or max. Es el esquema de agregación que usamos. \n",
    "En nuestro caso, por defecto usamos la media (**mean**)\n",
    "- $\\phi$ : Es la función de paso de mensajes. Se define en la funcion **message**.\n",
    "En nuestro caso:\n",
    "\n",
    "$$\\sigma (\\mathbf{P} \\cdot CONCAT(\\mathbf{h}_u,\\mathbf{e}_{uv})$$\n",
    "- $\\gamma$: Actualiza los embedings de cada nodo. Toma la salida de la AGREGACION  como primer argumento y cualquier argumento que se le pase a la función **propagate()**\n",
    "En nuestro caso:\n",
    "\n",
    "$$\\sigma (\\mathbf{Q} \\cdot CONCAT(\\mathbf{h}_u,\\mathbf{n}_{v})$$\n",
    "\n",
    "- Cuando se llama a **propagate()**, internamente se llama a la funciones **message()**, **aggregate()** y **update()**. Como argumentos básico se pasa **edge_index** y como adicionales pasamos todos los paremetros que necesiten las funciones anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "\n",
    "class EGraphSage(MessagePassing):\n",
    "    \"\"\"Non-minibatch version of GraphSage.\"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels,   #Dimension de entrada de los nodos\n",
    "                 out_channels,  #Dimension de salida de los nodos\n",
    "                 edge_channels, #Dimension de entrada de los arcos\n",
    "                 activation,    #Funcion de activacion (Ej: RELU)\n",
    "                 edge_mode,     #Forma en que se tratan los datos de arco. Esto hay que verlo\n",
    "                 normalize_emb, #True o False. Si se normalizan los valores del embeding\n",
    "                 aggr):         #Función de agregacion (ej: suma, media, max...)\n",
    "        \n",
    "        super(EGraphSage, self).__init__(aggr=aggr)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.edge_channels = edge_channels\n",
    "        self.edge_mode = edge_mode\n",
    "\n",
    "     \n",
    "        self.message_lin = nn.Linear(in_channels+edge_channels, \n",
    "                                     out_channels)\n",
    "        self.agg_lin = nn.Linear(in_channels+out_channels, \n",
    "                                 out_channels)\n",
    "\n",
    "        self.message_activation = get_activation(activation)\n",
    "        self.update_activation = get_activation(activation)\n",
    "        self.normalize_emb = normalize_emb\n",
    "    \n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_j has shape [E, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        m_j = torch.cat((x_j, edge_attr),dim=-1)\n",
    "        m_j = self.message_activation(self.message_lin(m_j))\n",
    "        return m_j\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        # x has shape [N, in_channels]\n",
    "        aggr_out = self.update_activation(self.agg_lin(torch.cat((aggr_out, x),dim=-1)))\n",
    "        if self.normalize_emb:\n",
    "            aggr_out = F.normalize(aggr_out, p=2, dim=-1) # Normaliza la salida (L2)\n",
    "        return aggr_out\n",
    "    \n",
    "    # !Ojo! Llamamos a esta funcion cuando usamos la capa convolucional y le pasamos\n",
    "    # los parámetros necesarios para el resto de funciones.\n",
    "    def forward(self, x, \n",
    "                edge_attr, \n",
    "                edge_index):\n",
    "        \n",
    "        num_nodes = x.size(0)\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        return self.propagate(edge_index, \n",
    "                              x=x, \n",
    "                              edge_attr=edge_attr, \n",
    "                              size=(num_nodes, num_nodes))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo completo (todas las capas) se genera usando la función **get_gnn**. Esta función devuelve una instancia de la clase **GNNStack**.\n",
    "\n",
    "- model_types: Son los tipos de GNN en cada capa. Veamos varios ejemplos:\n",
    "    * Ej de tres capas EGSAGE (el modelo analizado) --> Tendriamos una entrada de la forma **EGSAGE_EGSAGE_EGSAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gnn(data, args):\n",
    "    model_types = args.model_types.split('_') # Lista con las capas y tipo.\n",
    "    norm_embs = [True,]*len(model_types)      # Normaliza los embedings de todas las capas\n",
    "    post_hiddens = [args.node_dim]\n",
    "    \n",
    "    # Construye las distintas capas del modelo (crea el modelo completo)\n",
    "    model = GNNStack(data.num_node_features, # Atributos de nodo = Dimension del embeding del nodo = Atrib. de cada observacion\n",
    "                     data.edge_attr_dim,     # Atributos de arco = Dimension del embeding del arco = 1\n",
    "                     args.node_dim,          # La dimension del embeding de nodo a la salida de red(ej: 64)\n",
    "                     args.edge_dim,          # La dimension del embeding de arco a la salida de red(ej: 64)\n",
    "                     args.edge_mode,         # Determina como se opera con los arcos (default=1)\n",
    "                     model_types,            # Tipo de layer. En nuestro caso EGSAGE (hay mas tipos disponibles)\n",
    "                     args.dropout,           # Dropout de la MLP que actualiza el embedding de los nodos. \n",
    "                     args.gnn_activation,    # Funcion de activacion que usamos (ej: relu)\n",
    "                     args.concat_states,     # T o F. Indica si se concatenan los embeddings de cada layer\n",
    "                     post_hiddens,           # Capas ocultas de MLP que actualiza el embedding de los nodos. \n",
    "                     norm_embs,              # Lista bool. indicando si en una capa se normaliza embedding o no.\n",
    "                     args.aggr)              # Funcion de agregación (mean, sum, max...)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from utils.utils import get_activation\n",
    "import torch.nn as nn\n",
    "\n",
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 node_input_dim, \n",
    "                 edge_input_dim,\n",
    "                 node_dim, \n",
    "                 edge_dim, \n",
    "                 edge_mode,\n",
    "                 model_types, \n",
    "                 dropout, \n",
    "                 activation,\n",
    "                 concat_states, \n",
    "                 node_post_mlp_hiddens,\n",
    "                 normalize_embs, \n",
    "                 aggr):\n",
    "        \n",
    "        super(GNNStack, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.activation = activation\n",
    "        self.concat_states = concat_states\n",
    "        self.model_types = model_types\n",
    "        self.gnn_layer_num = len(model_types)\n",
    "\n",
    "        # convs\n",
    "        self.convs = self.build_convs(node_input_dim, \n",
    "                                      edge_input_dim,\n",
    "                                      node_dim, \n",
    "                                      edge_dim, \n",
    "                                      edge_mode,\n",
    "                                      model_types, \n",
    "                                      normalize_embs, \n",
    "                                      activation, \n",
    "                                      aggr)\n",
    "\n",
    "        \n",
    "        self.edge_update_mlps = self.build_edge_update_mlps(node_dim, \n",
    "                                                            edge_input_dim, \n",
    "                                                            edge_dim, \n",
    "                                                            self.gnn_layer_num, \n",
    "                                                            activation)\n",
    "        \n",
    "        # post node update\n",
    "        self.node_post_mlp = self.build_node_post_mlp(node_dim, \n",
    "                                                      node_dim, \n",
    "                                                      node_post_mlp_hiddens, \n",
    "                                                      dropout, \n",
    "                                                      activation)\n",
    "\n",
    "    def build_convs(self, node_input_dim, \n",
    "                    edge_input_dim,\n",
    "                    node_dim, \n",
    "                    edge_dim, \n",
    "                    edge_mode,\n",
    "                    model_types, \n",
    "                    normalize_embs, \n",
    "                    activation, aggr):\n",
    "        \n",
    "        convs = nn.ModuleList()\n",
    "        \n",
    "        # Primera capa convolucional\n",
    "        conv = self.build_conv_model(model_types[0],\n",
    "                                     node_input_dim,\n",
    "                                     node_dim,\n",
    "                                     edge_input_dim, \n",
    "                                     edge_mode, \n",
    "                                     normalize_embs[0], \n",
    "                                     activation, \n",
    "                                     aggr)\n",
    "        convs.append(conv)\n",
    "        \n",
    "        # Resto de las capas convolucionales\n",
    "        \n",
    "        for l in range(1,len(model_types)):\n",
    "            conv = self.build_conv_model(model_types[l],node_dim, node_dim,\n",
    "                                    edge_dim, edge_mode, normalize_embs[l], activation, aggr)\n",
    "            convs.append(conv)\n",
    "        \n",
    "        return convs\n",
    "    \n",
    "    def build_conv_model(self, model_type, \n",
    "                         node_in_dim, \n",
    "                         node_out_dim, \n",
    "                         edge_dim, \n",
    "                         edge_mode, \n",
    "                         normalize_emb, \n",
    "                         activation, \n",
    "                         aggr):\n",
    "        return EGraphSage(node_in_dim, node_out_dim, edge_dim, activation, \n",
    "                          edge_mode, normalize_emb, aggr)\n",
    "    \n",
    "    def build_node_post_mlp(self, input_dim, \n",
    "                            output_dim, \n",
    "                            hidden_dims, \n",
    "                            dropout, \n",
    "                            activation):\n",
    "        if 0 in hidden_dims:\n",
    "            return get_activation('none')\n",
    "        else:\n",
    "            layers = []\n",
    "            for hidden_dim in hidden_dims:\n",
    "                layer = nn.Sequential(\n",
    "                            nn.Linear(input_dim, hidden_dim),\n",
    "                            get_activation(activation),\n",
    "                            nn.Dropout(dropout),\n",
    "                            )\n",
    "                layers.append(layer)\n",
    "                input_dim = hidden_dim\n",
    "            layer = nn.Linear(input_dim, output_dim)\n",
    "            layers.append(layer)\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "\n",
    "    def build_edge_update_mlps(self, node_dim, edge_input_dim, edge_dim, gnn_layer_num, activation):\n",
    "        edge_update_mlps = nn.ModuleList()\n",
    "        edge_update_mlp = nn.Sequential(\n",
    "                nn.Linear(node_dim+node_dim+edge_input_dim,edge_dim),\n",
    "                get_activation(activation),\n",
    "                )\n",
    "        edge_update_mlps.append(edge_update_mlp)\n",
    "        for l in range(1,gnn_layer_num):\n",
    "            edge_update_mlp = nn.Sequential(\n",
    "                nn.Linear(node_dim+node_dim+edge_dim,edge_dim),\n",
    "                get_activation(activation),\n",
    "                )\n",
    "            edge_update_mlps.append(edge_update_mlp)\n",
    "        return edge_update_mlps\n",
    "\n",
    "    def update_edge_attr(self, x, edge_attr, edge_index, mlp):\n",
    "        x_i = x[edge_index[0],:]\n",
    "        x_j = x[edge_index[1],:]\n",
    "        edge_attr = mlp(torch.cat((x_i,x_j,edge_attr),dim=-1))\n",
    "        return edge_attr\n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index):\n",
    "        \n",
    "        for l, conv in enumerate(self.convs):\n",
    "            \n",
    "            # Actualiza estados (embedings) de los nodos\n",
    "            x = conv(x, edge_attr, edge_index)\n",
    "            # Actualiza embedings de los arcos\n",
    "            edge_attr = self.update_edge_attr(x, edge_attr, edge_index, self.edge_update_mlps[l])\n",
    "        \n",
    "        x = self.node_post_mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo ridículo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contruimos una matriz de dos observaciones y 3 atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1   A2   A3\n",
       "O1  1.0  2.0  3.0\n",
       "O2  4.0  5.0  6.0"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from uci.uci_data import *\n",
    "\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "X=np.array([[1.0,2,3],[4,5,6]])\n",
    "y=np.array([0,1])\n",
    "\n",
    "df_X=pd.DataFrame(X,columns=[\"A1\",\"A2\",\"A3\"],index=[\"O1\",\"O2\"])\n",
    "df_y=pd.DataFrame(y)\n",
    "\n",
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos los parámetros del grafo y llamamos a la funcion que lo crea.\n",
    "train_edge_prob= 0.7\n",
    "train_y_prob= 0.7\n",
    "seed=0\n",
    "normalize=False\n",
    "\n",
    "data = get_data(df_X, df_y, 0, train_edge_prob, 0, \n",
    "                    'y', train_y_prob, seed,normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1 1 2 3 4 2 3 4]\n",
      " [2 3 4 2 3 4 0 0 0 1 1 1]]\n",
      "[[1. 2. 3. 4. 5. 6. 1. 2. 3. 4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "#Mostramos los arcos y sus valores\n",
    "\n",
    "print(data.edge_index.numpy())\n",
    "print(data.edge_attr.numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O1(n0)</th>\n",
       "      <th>O2(n1)</th>\n",
       "      <th>F1(n2)</th>\n",
       "      <th>F2(n3)</th>\n",
       "      <th>F3(n4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   O1(n0)  O2(n1)  F1(n2)  F2(n3)  F3(n4)\n",
       "0       1       1       1       0       0\n",
       "1       1       1       0       1       0\n",
       "2       1       1       0       0       1"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos los valores iniciales de los embedings.\n",
    "pd.DataFrame(data.x.numpy().T.astype(int), columns=[\"O1(n0)\",\"O2(n1)\",\"F1(n2)\",\"F2(n3)\",\"F3(n4)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 5 nodos (n1,..., n5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "\n",
    "#Valor inicial de los embedings \n",
    "x = data.x.clone().detach().to(device)\n",
    "\n",
    "# Arcos de entrenamiento y su valor \n",
    "train_edge_index = data.train_edge_index.clone().detach().to(device)\n",
    "train_edge_attr = data.train_edge_attr.clone().detach().to(device)\n",
    "train_labels = data.train_labels.clone().detach().to(device)\n",
    "test_input_edge_index = train_edge_index\n",
    "test_input_edge_attr = train_edge_attr\n",
    "test_input_edge_labels = train_labels\n",
    "\n",
    "# Arcos de test y su valor.\n",
    "test_edge_index = data.test_edge_index.clone().detach().to(device)\n",
    "test_edge_attr = data.test_edge_attr.clone().detach().to(device)\n",
    "test_labels = data.test_labels.clone().detach().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los arcos del modelo con los que entrenamos son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 1. 0. 1.]\n",
      "  [0. 0. 1. 1. 1.]\n",
      "  [1. 1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [1. 1. 0. 0. 0.]]]\n",
      "tensor([[0, 0, 1, 1, 1, 2, 4, 2, 3, 4],\n",
      "        [2, 4, 2, 3, 4, 0, 0, 1, 1, 1]])\n",
      "tensor([1., 3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "print(to_dense_adj(train_edge_index,max_num_nodes=5).numpy())\n",
    "print(train_edge_index)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]]\n",
      "tensor([[0, 3],\n",
      "        [3, 0]])\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "print(to_dense_adj(test_edge_index,max_num_nodes=5).numpy())\n",
    "print(test_edge_index)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): EGraphSage(\n",
      "    (message_lin): Linear(in_features=4, out_features=6, bias=True)\n",
      "    (agg_lin): Linear(in_features=9, out_features=6, bias=True)\n",
      "    (message_activation): ReLU()\n",
      "    (update_activation): ReLU()\n",
      "  )\n",
      "  (1): EGraphSage(\n",
      "    (message_lin): Linear(in_features=12, out_features=6, bias=True)\n",
      "    (agg_lin): Linear(in_features=12, out_features=6, bias=True)\n",
      "    (message_activation): ReLU()\n",
      "    (update_activation): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Pasamos los distintos parámetros del modelo\n",
    "class paso_parametros:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "device='cpu'\n",
    "parametros_modelo = {\n",
    "    \"model_types\":'EGSAGE_EGSAGE',\n",
    "    \"node_dim\": 6,\n",
    "    \"edge_dim\": 6,\n",
    "    \"edge_mode\":1,\n",
    "    \"gnn_activation\":'relu',\n",
    "    \"concat_states\":False,\n",
    "    \"dropout\":0.,\n",
    "    \"aggr\":'mean'\n",
    "}\n",
    "#Generamos el modelo y lo mostramos\n",
    "model = get_gnn(data, paso_parametros(**parametros_modelo)).to(device)\n",
    "# Imprimimos el modelo GNN\n",
    "print(model.convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros del modelo GNN\n",
      "-----------\n",
      "Parametro: 0.message_lin.weight ----> Tamaño: torch.Size([6, 4])\n",
      "Parametro: 0.message_lin.bias ----> Tamaño: torch.Size([6])\n",
      "Parametro: 0.agg_lin.weight ----> Tamaño: torch.Size([6, 9])\n",
      "Parametro: 0.agg_lin.bias ----> Tamaño: torch.Size([6])\n",
      "Parametro: 1.message_lin.weight ----> Tamaño: torch.Size([6, 12])\n",
      "Parametro: 1.message_lin.bias ----> Tamaño: torch.Size([6])\n",
      "Parametro: 1.agg_lin.weight ----> Tamaño: torch.Size([6, 12])\n",
      "Parametro: 1.agg_lin.bias ----> Tamaño: torch.Size([6])\n",
      "-----------\n",
      "Parametros totales: 246\n",
      "\n",
      "Parametros del modelo Node_Post\n",
      "-----------\n",
      "Parametro: 0.0.weight ----> Tamaño: torch.Size([6, 6])\n",
      "Parametro: 0.0.bias ----> Tamaño: torch.Size([6])\n",
      "Parametro: 1.weight ----> Tamaño: torch.Size([6, 6])\n",
      "Parametro: 1.bias ----> Tamaño: torch.Size([6])\n",
      "-----------\n",
      "Parametros totales: 84\n"
     ]
    }
   ],
   "source": [
    "def imprime_parametros(capa):\n",
    "    sum_el=0\n",
    "    for name, param in capa.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            sum_el+=torch.numel(param)\n",
    "            print (\"Parametro:\", name,\"----> Tamaño:\",param.shape)\n",
    "    print(\"-----------\")\n",
    "    print(\"Parametros totales:\", sum_el)\n",
    "\n",
    "print(\"Parametros del modelo GNN\")\n",
    "print(\"-----------\")\n",
    "imprime_parametros(model.convs)\n",
    "print(\"\\nParametros del modelo Node_Post\")\n",
    "print(\"-----------\")\n",
    "imprime_parametros(model.node_post_mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una capa de tarea. Nos da la prediccion a nivel de arco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=12, out_features=6, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=1, bias=True)\n",
       "      (1): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.prediction_model import MLPNet\n",
    "# Esta red neuronal MLP tradicional que predice valores de arcos\n",
    "# La entrada son los embeddings de los extremos de un arco y la salida\n",
    "# el valor del atributo.\n",
    "\n",
    "impute_hiddens='6'\n",
    "impute_hiddens = list(map(int,impute_hiddens.split('_')))\n",
    "input_dim = parametros_modelo['node_dim'] * 2\n",
    "output_dim = 1\n",
    "impute_activation='relu'\n",
    "impute_model = MLPNet(input_dim, output_dim,\n",
    "                            hidden_layer_sizes=impute_hiddens,\n",
    "                            hidden_activation=impute_activation,\n",
    "                            dropout=parametros_modelo['dropout']).to(device)\n",
    "impute_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de utilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta funcion genera un tensor con los arcos conocidos con una probabilidad **known_prob**. Se usa una distribucion uniforme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Función get_known_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_known_mask(known_prob, edge_num):\n",
    "    known_mask = (torch.FloatTensor(edge_num, 1).uniform_() < known_prob).view(-1)\n",
    "    return known_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False,  True, False,  True, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False,  True,  True, False, False])\n",
      "\n",
      " El numero de arcos seleccionado es: 5\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo suponiendo una probabilidad del 20% y 20 elementos\n",
    "ej1=get_known_mask(0.2, 20)\n",
    "print(ej1)\n",
    "print(\"\\n El numero de arcos seleccionado es:\",sum(ej1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Función mask_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Devuelve un grupo de arcos donde la máscara es True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mask_edge(edge_index, edge_attr, mask, remove_edge):\n",
    "    edge_index = edge_index.clone().detach()\n",
    "    edge_attr = edge_attr.clone().detach()\n",
    "    if remove_edge:\n",
    "        edge_index = edge_index[:,mask]\n",
    "        edge_attr = edge_attr[mask]\n",
    "    else:\n",
    "        edge_attr[~mask] = 0.\n",
    "    return edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arcos a entrenar: 5\n",
      "Arcos conocidos: [False  True  True  True  True]\n",
      "Arcos a entrenar Total:\n",
      "[[0 0 1 1 1 2 4 2 3 4]\n",
      " [2 4 2 3 4 0 0 1 1 1]] \n",
      " [[1. 3. 4. 5. 6. 1. 3. 4. 5. 6.]]\n",
      "Arcos despues de Drop:\n",
      "[[0 1 1 1 4 2 3 4]\n",
      " [4 2 3 4 0 1 1 1]] \n",
      " [[3. 4. 5. 6. 3. 4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# Hacemos pruebas de la función con el dataset de juguete\n",
    "\n",
    "x = data.x.clone().detach().to(device)\n",
    "train_edge_index = data.train_edge_index.clone().detach().to(device)\n",
    "train_edge_attr = data.train_edge_attr.clone().detach().to(device)\n",
    "train_labels = data.train_labels.clone().detach().to(device)\n",
    "\n",
    "#Numero de arcos a entrenar\n",
    "num_arcos=int(train_edge_attr.shape[0]/2)\n",
    "print(\"Arcos a entrenar:\",num_arcos)\n",
    "\n",
    "# Sacamos los arcos conocidos con la funcion anterior\n",
    "arcos_conocidos=get_known_mask(0.7, num_arcos)\n",
    "print(\"Arcos conocidos:\", arcos_conocidos.numpy())\n",
    "\n",
    "known_edge_index, known_edge_attr = mask_edge(train_edge_index, train_edge_attr, \n",
    "                                              torch.cat((arcos_conocidos, arcos_conocidos), dim=0),True)\n",
    "print(\"Arcos a entrenar Total:\")\n",
    "print(train_edge_index.numpy(), \"\\n\",train_edge_attr.numpy().T)\n",
    "print(\"Arcos despues de Drop:\")\n",
    "print(known_edge_index.numpy(), \"\\n\",known_edge_attr.numpy().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Con las dos funciones anteriores simulamos $\\epsilon_{drop}=DropEdge(\\epsilon, r_{drop})$ necesario para ejecutar el algoritmo. En nuestro caso $r_{drop}=1-known$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "known=0.7 #Probabilidad de conocer el valor del atributo del arco (rdrop=1-known)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#Creamos un optimizador Adam, lr=0.001 y weigh_decay=0.\n",
    "filter_fn = filter(lambda p : p.requires_grad, list(model.parameters()))\n",
    "opt=optimizer = optim.Adam(filter_fn, lr=0.001, weight_decay=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numero de epochs\n",
    "epochs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss final:0.16727885603904724\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    impute_model.train()\n",
    "    \n",
    "    # Obtenemos los arcos que usaremos para el entrenamiento\n",
    "    known_mask = get_known_mask(known, int(train_edge_attr.shape[0] / 2)).to(device)\n",
    "    double_known_mask = torch.cat((known_mask, known_mask), dim=0)\n",
    "    known_edge_index, known_edge_attr = mask_edge(train_edge_index, train_edge_attr, \n",
    "                                                  double_known_mask, True)\n",
    "    #################\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    # Calculamos el embeding del nodo\n",
    "    x_embd = model(x, known_edge_attr, known_edge_index) # Dimensiones 519x64\n",
    "    \n",
    "    # Predecimos la etiqueta del arco\n",
    "    pred = impute_model([x_embd[train_edge_index[0]], x_embd[train_edge_index[1]]]) #Dimensiones 9318x1\n",
    "    pred_train = pred[:int(train_edge_attr.shape[0] / 2),0] # Dimensiones 4659\n",
    "    \n",
    "    # Calculamos la perdida del arco.\n",
    "    label_train = train_labels\n",
    "    loss = F.mse_loss(pred_train, label_train)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "print(\"Loss final:{}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vemos salidas del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "impute_model.eval()\n",
    "with torch.no_grad():\n",
    "    x_embd = model(x, test_input_edge_attr, test_input_edge_index)\n",
    "    pred = impute_model([x_embd[test_edge_index[0], :], x_embd[test_edge_index[1], :]])\n",
    "    pred_test = pred[:int(test_edge_attr.shape[0] / 2),0]\n",
    "    label_test = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los embedings de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3663, -4.9983, -1.2062, -4.9983, -4.9983],\n",
       "        [ 3.2973,  9.3100,  2.9202,  9.3100,  9.3100],\n",
       "        [-2.9129, -8.9212, -2.5918, -8.9212, -8.9212],\n",
       "        [-3.3403, -9.4328, -2.7771, -9.4328, -9.4328],\n",
       "        [ 2.9541, 10.2637,  2.4039, 10.2637, 10.2637],\n",
       "        [-3.0347, -6.9766, -2.1346, -6.9766, -6.9766]])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embd.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3])\n",
      "tensor([3, 0])\n",
      "tensor([[-1.3663, -4.9983],\n",
      "        [ 3.2973,  9.3100],\n",
      "        [-2.9129, -8.9212],\n",
      "        [-3.3403, -9.4328],\n",
      "        [ 2.9541, 10.2637],\n",
      "        [-3.0347, -6.9766]])\n"
     ]
    }
   ],
   "source": [
    "print(test_edge_index[0])\n",
    "print(test_edge_index[1])\n",
    "print(x_embd[test_edge_index[0], :].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6118],\n",
       "        [4.4722]])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es curioso que se quedan con el primer valor...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.6118])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:int(test_edge_attr.shape[0] / 2),0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La etiqueta real del arco seria\n",
    "label_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
