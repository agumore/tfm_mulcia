{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Cargamos librerías\n",
    "# Librería para representacion de grafos\n",
    "import networkx as nx \n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Librería con modelo GNN y utilidades\n",
    "\n",
    "from utils import *\n",
    "from uci.uci_data import *\n",
    "from models.gnn_model import get_gnn\n",
    "from models.prediction_model import MLPNet\n",
    "from utils.utils import build_optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Definimos una funcion para pasar parametros a las distintas funciones implementadas por los autores\n",
    "\n",
    "class paso_parametros:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# Concrete\n",
    "\n",
    "(Mirar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Carga datos de dataset Housing\n",
    "uci_path='/notebooks/datasets'\n",
    "df_np = np.loadtxt(uci_path+'/{}/data.txt'.format('concrete'))\n",
    "df_y = pd.DataFrame(df_np[:, -1:])\n",
    "df_X = pd.DataFrame(df_np[:, :-1])\n",
    "\n",
    "#Definimos los parámetros del grafo\n",
    "node_mode=0\n",
    "train_edge=0.7\n",
    "split_sample=0.\n",
    "split_by='y'\n",
    "train_y=0.7\n",
    "seed=np.random.rand()\n",
    "normalize=True\n",
    "\n",
    "#Generamos el grafo\n",
    "data = get_data(df_X, df_y, node_mode, train_edge, split_sample, \n",
    "                    split_by, train_y, seed,normalize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EGSAGE', 'EGSAGE', 'EGSAGE'] [True, True, True] [64]\n",
      "GNNStack(\n",
      "  (convs): ModuleList(\n",
      "    (0): EGraphSage(\n",
      "      (message_lin): Linear(in_features=9, out_features=64, bias=True)\n",
      "      (agg_lin): Linear(in_features=72, out_features=64, bias=True)\n",
      "      (message_activation): ReLU()\n",
      "      (update_activation): ReLU()\n",
      "    )\n",
      "    (1): EGraphSage(\n",
      "      (message_lin): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (agg_lin): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (message_activation): ReLU()\n",
      "      (update_activation): ReLU()\n",
      "    )\n",
      "    (2): EGraphSage(\n",
      "      (message_lin): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (agg_lin): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (message_activation): ReLU()\n",
      "      (update_activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (node_post_mlp): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (edge_update_mlps): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=129, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class paso_parametros:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "#Pasamos los distintos parámetros del modelo        \n",
    "parametros_modelo = {\n",
    "    \"model_types\":'EGSAGE_EGSAGE_EGSAGE',\n",
    "    \"norm_embs\":None,\n",
    "    \"post_hiddens\":None,\n",
    "    \"node_dim\": 64,\n",
    "    \"edge_dim\":64,\n",
    "    \"edge_mode\":1,\n",
    "    \"gnn_activation\":'relu',\n",
    "    \"concat_states\":False,\n",
    "    \"dropout\":0.,\n",
    "    \"aggr\":'mean'\n",
    "}    \n",
    "device='cuda'\n",
    "\n",
    "#Generamos el modelo y lo mostramos\n",
    "model = get_gnn(data, paso_parametros(**parametros_modelo)).to(device)\n",
    "\n",
    "# Imprimimos el modelo\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (1): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esta red neuronal asigna valores a los arcos\n",
    "impute_hiddens='64'\n",
    "impute_hiddens = list(map(int,impute_hiddens.split('_')))\n",
    "input_dim = parametros_modelo['node_dim'] * 2\n",
    "output_dim = 1\n",
    "impute_activation='relu'\n",
    "impute_model = MLPNet(input_dim, output_dim,\n",
    "                            hidden_layer_sizes=impute_hiddens,\n",
    "                            hidden_activation=impute_activation,\n",
    "                            dropout=parametros_modelo['dropout']).to(device)\n",
    "impute_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros del modelo GNN\n",
      "-----------\n",
      "convs.0.message_lin.weight torch.Size([64, 9])\n",
      "convs.0.message_lin.bias torch.Size([64])\n",
      "convs.0.agg_lin.weight torch.Size([64, 72])\n",
      "convs.0.agg_lin.bias torch.Size([64])\n",
      "convs.1.message_lin.weight torch.Size([64, 128])\n",
      "convs.1.message_lin.bias torch.Size([64])\n",
      "convs.1.agg_lin.weight torch.Size([64, 128])\n",
      "convs.1.agg_lin.bias torch.Size([64])\n",
      "convs.2.message_lin.weight torch.Size([64, 128])\n",
      "convs.2.message_lin.bias torch.Size([64])\n",
      "convs.2.agg_lin.weight torch.Size([64, 128])\n",
      "convs.2.agg_lin.bias torch.Size([64])\n",
      "node_post_mlp.0.0.weight torch.Size([64, 64])\n",
      "node_post_mlp.0.0.bias torch.Size([64])\n",
      "node_post_mlp.1.weight torch.Size([64, 64])\n",
      "node_post_mlp.1.bias torch.Size([64])\n",
      "edge_update_mlps.0.0.weight torch.Size([64, 129])\n",
      "edge_update_mlps.0.0.bias torch.Size([64])\n",
      "edge_update_mlps.1.0.weight torch.Size([64, 192])\n",
      "edge_update_mlps.1.0.bias torch.Size([64])\n",
      "edge_update_mlps.2.0.weight torch.Size([64, 192])\n",
      "edge_update_mlps.2.0.bias torch.Size([64])\n",
      "+++++++++++\n",
      "Parametros del modelo Impute model\n",
      "-----------\n",
      "layers.0.0.weight torch.Size([64, 128])\n",
      "layers.0.0.bias torch.Size([64])\n",
      "layers.1.0.weight torch.Size([1, 64])\n",
      "layers.1.0.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "#Podemos ver los parametros de los dos modelos.\n",
    "print(\"Parametros del modelo GNN\")\n",
    "print(\"-----------\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name,param.shape)\n",
    "print(\"+++++++++++\")\n",
    "print(\"Parametros del modelo Impute model\")\n",
    "print(\"-----------\")\n",
    "for name, param in impute_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.shape)\n",
    "\n",
    "#Unimos los parametros\n",
    "trainable_parameters = list(model.parameters()) + list(impute_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "epochs=20000\n",
    "known=0.7 #Probabilidad de conocer el valor del atributo del arco (rdrop=1-known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizamos los datos del entrenamiento\n",
    "\n",
    "x = data.x.clone().detach().to(device)\n",
    "all_train_edge_index = data.train_edge_index.clone().detach().to(device)\n",
    "all_train_edge_attr = data.train_edge_attr.clone().detach().to(device)\n",
    "all_train_labels = data.train_labels.clone().detach().to(device)\n",
    "train_edge_index, train_edge_attr, train_labels = all_train_edge_index, \\\n",
    "                                                  all_train_edge_attr, \\\n",
    "                                                  all_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1305, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Loss final:0.005366150289773941\n"
     ]
    }
   ],
   "source": [
    "########################### NO ejecutar \n",
    "\n",
    "\n",
    "#Parametros del optimizador.\n",
    "parametros_opt = {\n",
    "    \"opt\":'adam',\n",
    "    \"weight_decay\":0.,\n",
    "    \"lr\":0.001,\n",
    "    \"opt_scheduler\":'none',\n",
    "    \"opt_decay_step\":1000,\n",
    "    \"opt_decay_rate\":0.9\n",
    "}    \n",
    "# build optimizer\n",
    "scheduler, opt = build_optimizer(paso_parametros(**parametros_opt), trainable_parameters)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    impute_model.train()\n",
    "    \n",
    "    # Obtenemos los arcos para los que sabemos el valor de su atributo\n",
    "    known_mask = get_known_mask(known, int(train_edge_attr.shape[0] / 2)).to(device)\n",
    "    double_known_mask = torch.cat((known_mask, known_mask), dim=0)\n",
    "    known_edge_index, known_edge_attr = mask_edge(train_edge_index, train_edge_attr, \n",
    "                                                  double_known_mask, True)\n",
    "    #################\n",
    "    opt.zero_grad()\n",
    "    # Calculamos el embeding del nodo\n",
    "    x_embd = model(x, known_edge_attr, known_edge_index) # Dimensiones 519x64\n",
    "    # Predecimos la etiqueta del arco\n",
    "    pred = impute_model([x_embd[train_edge_index[0]], x_embd[train_edge_index[1]]]) #Dimensiones 9318x1\n",
    "    pred_train = pred[:int(train_edge_attr.shape[0] / 2),0] # Dimensiones 4659\n",
    "    # Comparamos con la etiqueta real del arco\n",
    "    label_train = train_labels\n",
    "    loss = F.mse_loss(pred_train, label_train)\n",
    "    if epoch%500==1:\n",
    "        print(loss)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "print(\"Loss final:{}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Grabamos el modelo #### Dejamos comentado\n",
    "#torch.save(model.state_dict(), uci_path+'/concrete/saved_model/model')\n",
    "#torch.save(impute_model.state_dict(), uci_path+'/concrete/saved_model/impute_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargado el modelo\n",
    "model.load_state_dict(torch.load(uci_path+'/concrete/saved_model/model',\n",
    "                                 map_location=torch.device(device)))\n",
    "impute_model.load_state_dict(torch.load(uci_path+'/concrete/saved_model/impute_model',\n",
    "                                        map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.01805456541478634 RMSE: 0.13436727806570445 MAE: 0.08584008365869522\n"
     ]
    }
   ],
   "source": [
    "#Evaluamos el modelo\n",
    "x = data.x.clone().detach().to(device)\n",
    "all_train_edge_index = data.train_edge_index.clone().detach().to(device)\n",
    "all_train_edge_attr = data.train_edge_attr.clone().detach().to(device)\n",
    "all_train_labels = data.train_labels.clone().detach().to(device)\n",
    "test_input_edge_index = all_train_edge_index\n",
    "test_input_edge_attr = all_train_edge_attr\n",
    "test_edge_index = data.test_edge_index.clone().detach().to(device)\n",
    "test_edge_attr = data.test_edge_attr.clone().detach().to(device)\n",
    "test_labels = data.test_labels.clone().detach().to(device)\n",
    "\n",
    "model.eval()\n",
    "impute_model.eval()\n",
    "with torch.no_grad():\n",
    "    x_embd = model(x, test_input_edge_attr, test_input_edge_index)\n",
    "    pred = impute_model([x_embd[test_edge_index[0], :], x_embd[test_edge_index[1], :]])\n",
    "    pred_test = pred[:int(test_edge_attr.shape[0] / 2),0]\n",
    "    label_test = test_labels\n",
    "    mse = F.mse_loss(pred_test, label_test)\n",
    "    test_rmse = np.sqrt(mse.item())\n",
    "    l1 = F.l1_loss(pred_test, label_test)\n",
    "    test_l1 = l1.item()\n",
    "print(\"MSE: {} RMSE: {} MAE: {}\".format(mse.item(), test_rmse,test_l1))\n",
    "\n",
    "# Guardamos MAE y RMSE en una lista\n",
    "val_GRAPE=[test_l1, test_rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.07417582720518112, 0.39649415016174316, 0.38081395626068115, 0.7390109896659851]\n",
      "[-0.010777436196804047, 0.11525193601846695, 0.3995210826396942, 0.3706745505332947, 0.20539426803588867]\n"
     ]
    }
   ],
   "source": [
    "# Por curiosidad mostramos como serian las 5 primeras etiquetas vs sus prediciones\n",
    "print(label_test[0:5].tolist())\n",
    "print(pred_test[0:5].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# ¿Estos valores son buenos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "Comparamos con otros métodos de imputacion de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Utilizamos los parametros para los que sabemos sus valores\n",
    "train_edge_mask = data.train_edge_mask.numpy()\n",
    "\n",
    "#Obtenemos las matrices de parametros completos e incompletos\n",
    "from utils.utils import construct_missing_X_from_mask\n",
    "X, X_incomplete = construct_missing_X_from_mask(train_edge_mask, data.df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset completo: \n",
      "[1.         0.         0.         0.32108626 0.07763975]\n",
      "Dataset incompleto: \n",
      "[1.                nan 0.         0.32108626 0.07763975]\n"
     ]
    }
   ],
   "source": [
    "#Vemos un ejemplo con la primera observacion\n",
    "print(\"Dataset completo: \\n{}\".format(X[0][0:5]))\n",
    "print(\"Dataset incompleto: \\n{}\".format(X_incomplete[0][0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Para los distintos métodos de imputacion, los autores utilizan\n",
    "# la libreria \"fancyimpute\" con distintos métodos\n",
    "\n",
    "from fancyimpute import SimpleFill, KNN, IterativeImputer, IterativeSVD, SoftImpute\n",
    "\n",
    "# Función para imputar valores\n",
    "def baseline_inpute(X_incomplete, method='mean',level=0):\n",
    "\n",
    "    if method == 'mean':\n",
    "        X_filled_mean = SimpleFill().fit_transform(X_incomplete)\n",
    "        return X_filled_mean\n",
    "    elif method == 'knn':\n",
    "        k = [3,10,50][level]\n",
    "        X_filled_knn = KNN(k=k, verbose=False).fit_transform(X_incomplete)\n",
    "        return X_filled_knn\n",
    "    elif method == 'svd':\n",
    "        rank = [np.ceil((X_incomplete.shape[1]-1)/10),np.ceil((X_incomplete.shape[1]-1)/5),X_incomplete.shape[1]-1][level]\n",
    "        X_filled_svd = IterativeSVD(rank=int(rank),verbose=False).fit_transform(X_incomplete)\n",
    "        return X_filled_svd\n",
    "    elif method == 'mice':\n",
    "        max_iter = [3,10,50][level]\n",
    "        X_filled_mice = IterativeImputer(max_iter=max_iter).fit_transform(X_incomplete)\n",
    "        return X_filled_mice\n",
    "    elif method == 'spectral':\n",
    "        # default value for the sparsity level is with respect to the maximum singular value,\n",
    "        # this is now done in a heuristic way\n",
    "        sparsity = [0.5,None,3][level]\n",
    "        X_filled_spectral = SoftImpute(shrinkage_value=sparsity).fit_transform(X_incomplete)\n",
    "        return X_filled_spectral\n",
    "    else:\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Como primer ejemplo, usamos la media para imputar los valores.\n",
    "method='mean'\n",
    "level=0\n",
    "X_filled = baseline_inpute(X_incomplete, method,level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset completo: \n",
      "[1.         0.         0.         0.32108626 0.07763975 0.69476744]\n",
      "Dataset incompleto: \n",
      "[1.                nan 0.         0.32108626 0.07763975 0.69476744]\n",
      "Dataset relleno: \n",
      "[1.         0.20666578 0.         0.32108626 0.07763975 0.69476744]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset completo: \\n{}\".format(X[0][0:6]))\n",
    "print(\"Dataset incompleto: \\n{}\".format(X_incomplete[0][0:6]))\n",
    "print(\"Dataset relleno: \\n{}\".format(X_filled[0][0:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "mask = np.isnan(X_incomplete)\n",
    "diff = X[mask] - X_filled[mask]\n",
    "mae = np.mean(np.abs(diff))\n",
    "rmse = np.sqrt(np.mean(diff**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18318570560922315 0.2268964245046732\n"
     ]
    }
   ],
   "source": [
    "print(mae, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos para todos los métodos tratados en el articulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Max Singular Value of X_init = 23.897300\n",
      "[SoftImpute] Iter 1: observed MAE=0.012911 rank=8\n",
      "[SoftImpute] Iter 2: observed MAE=0.012953 rank=8\n",
      "[SoftImpute] Iter 3: observed MAE=0.012995 rank=8\n",
      "[SoftImpute] Iter 4: observed MAE=0.013035 rank=8\n",
      "[SoftImpute] Iter 5: observed MAE=0.013074 rank=8\n",
      "[SoftImpute] Iter 6: observed MAE=0.013111 rank=8\n",
      "[SoftImpute] Iter 7: observed MAE=0.013147 rank=8\n",
      "[SoftImpute] Iter 8: observed MAE=0.013180 rank=8\n",
      "[SoftImpute] Iter 9: observed MAE=0.013212 rank=8\n",
      "[SoftImpute] Iter 10: observed MAE=0.013242 rank=8\n",
      "[SoftImpute] Iter 11: observed MAE=0.013270 rank=8\n",
      "[SoftImpute] Iter 12: observed MAE=0.013296 rank=8\n",
      "[SoftImpute] Iter 13: observed MAE=0.013321 rank=8\n",
      "[SoftImpute] Iter 14: observed MAE=0.013345 rank=8\n",
      "[SoftImpute] Iter 15: observed MAE=0.013367 rank=8\n",
      "[SoftImpute] Iter 16: observed MAE=0.013388 rank=8\n",
      "[SoftImpute] Iter 17: observed MAE=0.013408 rank=8\n",
      "[SoftImpute] Iter 18: observed MAE=0.013427 rank=8\n",
      "[SoftImpute] Iter 19: observed MAE=0.013444 rank=8\n",
      "[SoftImpute] Iter 20: observed MAE=0.013460 rank=8\n",
      "[SoftImpute] Iter 21: observed MAE=0.013476 rank=8\n",
      "[SoftImpute] Iter 22: observed MAE=0.013491 rank=8\n",
      "[SoftImpute] Iter 23: observed MAE=0.013505 rank=8\n",
      "[SoftImpute] Iter 24: observed MAE=0.013518 rank=8\n",
      "[SoftImpute] Iter 25: observed MAE=0.013531 rank=8\n",
      "[SoftImpute] Iter 26: observed MAE=0.013543 rank=8\n",
      "[SoftImpute] Iter 27: observed MAE=0.013554 rank=8\n",
      "[SoftImpute] Iter 28: observed MAE=0.013564 rank=8\n",
      "[SoftImpute] Iter 29: observed MAE=0.013573 rank=8\n",
      "[SoftImpute] Iter 30: observed MAE=0.013582 rank=8\n",
      "[SoftImpute] Iter 31: observed MAE=0.013591 rank=8\n",
      "[SoftImpute] Iter 32: observed MAE=0.013598 rank=8\n",
      "[SoftImpute] Iter 33: observed MAE=0.013606 rank=8\n",
      "[SoftImpute] Iter 34: observed MAE=0.013612 rank=8\n",
      "[SoftImpute] Iter 35: observed MAE=0.013619 rank=8\n",
      "[SoftImpute] Iter 36: observed MAE=0.013625 rank=8\n",
      "[SoftImpute] Iter 37: observed MAE=0.013630 rank=8\n",
      "[SoftImpute] Iter 38: observed MAE=0.013635 rank=8\n",
      "[SoftImpute] Iter 39: observed MAE=0.013640 rank=8\n",
      "[SoftImpute] Iter 40: observed MAE=0.013644 rank=8\n",
      "[SoftImpute] Iter 41: observed MAE=0.013648 rank=8\n",
      "[SoftImpute] Iter 42: observed MAE=0.013652 rank=8\n",
      "[SoftImpute] Iter 43: observed MAE=0.013655 rank=8\n",
      "[SoftImpute] Iter 44: observed MAE=0.013659 rank=8\n",
      "[SoftImpute] Iter 45: observed MAE=0.013662 rank=8\n",
      "[SoftImpute] Iter 46: observed MAE=0.013664 rank=8\n",
      "[SoftImpute] Iter 47: observed MAE=0.013667 rank=8\n",
      "[SoftImpute] Iter 48: observed MAE=0.013669 rank=8\n",
      "[SoftImpute] Iter 49: observed MAE=0.013672 rank=8\n",
      "[SoftImpute] Iter 50: observed MAE=0.013674 rank=8\n",
      "[SoftImpute] Iter 51: observed MAE=0.013675 rank=8\n",
      "[SoftImpute] Iter 52: observed MAE=0.013677 rank=8\n",
      "[SoftImpute] Iter 53: observed MAE=0.013679 rank=8\n",
      "[SoftImpute] Iter 54: observed MAE=0.013680 rank=8\n",
      "[SoftImpute] Iter 55: observed MAE=0.013681 rank=8\n",
      "[SoftImpute] Iter 56: observed MAE=0.013682 rank=8\n",
      "[SoftImpute] Iter 57: observed MAE=0.013684 rank=8\n",
      "[SoftImpute] Iter 58: observed MAE=0.013685 rank=8\n",
      "[SoftImpute] Iter 59: observed MAE=0.013685 rank=8\n",
      "[SoftImpute] Iter 60: observed MAE=0.013686 rank=8\n",
      "[SoftImpute] Iter 61: observed MAE=0.013687 rank=8\n",
      "[SoftImpute] Iter 62: observed MAE=0.013688 rank=8\n",
      "[SoftImpute] Iter 63: observed MAE=0.013688 rank=8\n",
      "[SoftImpute] Iter 64: observed MAE=0.013689 rank=8\n",
      "[SoftImpute] Iter 65: observed MAE=0.013690 rank=8\n",
      "[SoftImpute] Iter 66: observed MAE=0.013690 rank=8\n",
      "[SoftImpute] Iter 67: observed MAE=0.013691 rank=8\n",
      "[SoftImpute] Iter 68: observed MAE=0.013691 rank=8\n",
      "[SoftImpute] Iter 69: observed MAE=0.013691 rank=8\n",
      "[SoftImpute] Iter 70: observed MAE=0.013692 rank=8\n",
      "[SoftImpute] Iter 71: observed MAE=0.013692 rank=8\n",
      "[SoftImpute] Iter 72: observed MAE=0.013692 rank=8\n",
      "[SoftImpute] Iter 73: observed MAE=0.013693 rank=8\n",
      "[SoftImpute] Iter 74: observed MAE=0.013693 rank=8\n",
      "[SoftImpute] Iter 75: observed MAE=0.013693 rank=8\n",
      "[SoftImpute] Iter 76: observed MAE=0.013693 rank=8\n",
      "[SoftImpute] Iter 77: observed MAE=0.013693 rank=8\n",
      "[SoftImpute] Iter 78: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 79: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 80: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 81: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 82: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 83: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 84: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 85: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 86: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 87: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 88: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 89: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 90: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 91: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 92: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 93: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 94: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 95: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 96: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 97: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 98: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 99: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 100: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Stopped after iteration 100 for lambda=0.477946\n"
     ]
    }
   ],
   "source": [
    "best_levels = {'mean':0, 'knn':2, 'mice':0, 'svd':2, 'spectral':1}\n",
    "\n",
    "# Probamos todos los métodos y los guardamos en una lista\n",
    "val_baseline=[]\n",
    "for method in ['mean', 'knn', 'mice', 'svd', 'spectral']:\n",
    "    level = best_levels[method]\n",
    "    #print(\"using best level {} for {}\".format(level,method))\n",
    "    X_filled = baseline_inpute(X_incomplete, method,level)\n",
    "    mask = np.isnan(X_incomplete)\n",
    "    diff = X[mask] - X_filled[mask]\n",
    "    mae = np.mean(np.abs(diff))\n",
    "    rmse = np.sqrt(np.mean(diff**2))\n",
    "    val_baseline.append([mae, rmse])\n",
    "#Añadimos el valor de la GNN\n",
    "val_baseline.append(val_GRAPE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.183186</td>\n",
       "      <td>0.226896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.113983</td>\n",
       "      <td>0.170853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svd</th>\n",
       "      <td>0.136741</td>\n",
       "      <td>0.183556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mice</th>\n",
       "      <td>0.196686</td>\n",
       "      <td>0.258173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectral</th>\n",
       "      <td>0.200432</td>\n",
       "      <td>0.262162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grape</th>\n",
       "      <td>0.085840</td>\n",
       "      <td>0.134367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mae      rmse\n",
       "mean      0.183186  0.226896\n",
       "knn       0.113983  0.170853\n",
       "svd       0.136741  0.183556\n",
       "mice      0.196686  0.258173\n",
       "spectral  0.200432  0.262162\n",
       "grape     0.085840  0.134367"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=pd.DataFrame(val_baseline, columns=['mae','rmse'], index=['mean', 'knn', 'svd', 'mice', 'spectral','grape'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normalizamos mae y representamos\n",
    "import seaborn as sns\n",
    "df2=df\n",
    "df2['mae']=df['mae']/df['mae']['mean']\n",
    "\n",
    "g=sns.catplot(kind=\"bar\", data=df2.T[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecimos Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EGSAGE', 'EGSAGE'] [True, True] [16]\n",
      "GNNStack(\n",
      "  (convs): ModuleList(\n",
      "    (0): EGraphSage(\n",
      "      (message_lin): Linear(in_features=9, out_features=16, bias=True)\n",
      "      (agg_lin): Linear(in_features=24, out_features=16, bias=True)\n",
      "      (message_activation): ReLU()\n",
      "      (update_activation): ReLU()\n",
      "    )\n",
      "    (1): EGraphSage(\n",
      "      (message_lin): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (agg_lin): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (message_activation): ReLU()\n",
      "      (update_activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (node_post_mlp): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
      "  )\n",
      "  (edge_update_mlps): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=33, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=48, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MLPNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=1, bias=True)\n",
      "      (1): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MLPNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=1, bias=True)\n",
      "      (1): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Pasamos los distintos parámetros del modelo        \n",
    "parametros_modelo = {\n",
    "    \"model_types\":'EGSAGE_EGSAGE',\n",
    "    \"norm_embs\":None,\n",
    "    \"post_hiddens\":None,\n",
    "    \"node_dim\": 16,\n",
    "    \"edge_dim\":16,\n",
    "    \"edge_mode\":1,\n",
    "    \"gnn_activation\":'relu',\n",
    "    \"concat_states\":False,\n",
    "    \"dropout\":0.,\n",
    "    \"aggr\":'mean'\n",
    "}    \n",
    "device='cuda'\n",
    "\n",
    "#Generamos el modelo y lo mostramos\n",
    "model_y = get_gnn(data, paso_parametros(**parametros_modelo)).to(device)\n",
    "\n",
    "# Imprimimos el modelo\n",
    "print(model_y)\n",
    "\n",
    "# Esta red neuronal asigna valores a los arcos\n",
    "impute_hiddens=''\n",
    "input_dim = parametros_modelo['node_dim'] * 2\n",
    "output_dim = 1\n",
    "impute_activation='relu'\n",
    "impute_model_y = MLPNet(input_dim, output_dim,\n",
    "                            hidden_layer_sizes=impute_hiddens,\n",
    "                            hidden_activation=impute_activation,\n",
    "                            dropout=parametros_modelo['dropout']).to(device)\n",
    "print(impute_model_y)\n",
    "\n",
    "\n",
    "# Esta red neuronal asigna valores de 'y'\n",
    "n_row, n_col = data.df_X.shape\n",
    "predict_hiddens = []\n",
    "predict_model = MLPNet(n_col, 1,\n",
    "                           hidden_layer_sizes=predict_hiddens,\n",
    "                           dropout=parametros_modelo['dropout']).to(device)\n",
    "\n",
    "print(predict_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Parametros a entrenar\n",
    "trainable_parameters = list(model_y.parameters()) \\\n",
    "                           + list(impute_model_y.parameters()) \\\n",
    "                           + list(predict_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "epochs=20000\n",
    "known=0.7 #Probabilidad de conocer el valor del atributo del arco (rdrop=1-known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all y num is 1030, train num is 689, test num is 341\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos del modelo\n",
    "x = data.x.clone().detach().to(device)\n",
    "y = data.y.clone().detach().to(device)\n",
    "edge_index = data.edge_index.clone().detach().to(device)\n",
    "train_edge_index = data.train_edge_index.clone().detach().to(device)\n",
    "train_edge_attr = data.train_edge_attr.clone().detach().to(device)\n",
    "\n",
    "train_y_mask = data.train_y_mask.clone().detach().to(device)\n",
    "test_y_mask = data.test_y_mask.clone().detach().to(device)\n",
    "print(\"all y num is {}, train num is {}, test num is {}\"\\\n",
    "                .format(\n",
    "                train_y_mask.shape[0],torch.sum(train_y_mask),\n",
    "                torch.sum(test_y_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(1547.4951, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "501 tensor(162.2447, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "1001 tensor(139.5123, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "1501 tensor(147.2539, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "2001 tensor(142.3166, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "2501 tensor(139.3578, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "3001 tensor(141.4554, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "3501 tensor(138.9312, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "4001 tensor(133.9850, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "4501 tensor(134.0546, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "5001 tensor(137.8888, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "5501 tensor(140.5211, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "6001 tensor(138.5962, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "6501 tensor(122.5134, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "7001 tensor(146.2840, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "7501 tensor(124.8079, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "8001 tensor(119.9101, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "8501 tensor(134.8681, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "9001 tensor(119.5033, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "9501 tensor(127.5388, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "10001 tensor(137.9292, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "10501 tensor(130.3864, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "11001 tensor(123.9933, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "11501 tensor(129.4161, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "12001 tensor(134.8814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "12501 tensor(127.9834, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "13001 tensor(121.0239, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "13501 tensor(133.0651, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "14001 tensor(129.7684, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "14501 tensor(112.0108, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "15001 tensor(117.2085, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "15501 tensor(118.9366, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "16001 tensor(127.5909, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "16501 tensor(107.0368, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "17001 tensor(114.0556, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "17501 tensor(111.6865, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "18001 tensor(112.0456, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "18501 tensor(123.7257, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "19001 tensor(111.4912, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "19501 tensor(107.5163, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Parametros del optimizador.\n",
    "parametros_opt = {\n",
    "    \"opt\":'adam',\n",
    "    \"weight_decay\":0.,\n",
    "    \"lr\":0.001,\n",
    "    \"opt_scheduler\":'none',\n",
    "    \"opt_decay_step\":1000,\n",
    "    \"opt_decay_rate\":0.9\n",
    "} \n",
    "\n",
    "\n",
    "# build optimizer\n",
    "scheduler, opt = build_optimizer(paso_parametros(**parametros_opt), trainable_parameters)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_y.train()\n",
    "    impute_model_y.train()\n",
    "    predict_model.train()\n",
    "\n",
    "    known_mask = get_known_mask(known, int(train_edge_attr.shape[0] / 2)).to(device)\n",
    "    double_known_mask = torch.cat((known_mask, known_mask), dim=0)\n",
    "    known_edge_index, known_edge_attr = mask_edge(train_edge_index, train_edge_attr, double_known_mask, True)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    x_embd = model_y(x, known_edge_attr, known_edge_index)\n",
    "    X = impute_model_y([x_embd[edge_index[0, :int(n_row * n_col)]], x_embd[edge_index[1, :int(n_row * n_col)]]])\n",
    "    X = torch.reshape(X, [n_row, n_col])\n",
    "    pred = predict_model(X)[:, 0]\n",
    "    pred_train = pred[train_y_mask]\n",
    "    label_train = y[train_y_mask]\n",
    "\n",
    "    loss = F.mse_loss(pred_train, label_train)\n",
    "    if epoch%500==1:\n",
    "        print(epoch,loss)\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grabamos el modelo #### Dejamos comentado\n",
    "torch.save(model.state_dict(), uci_path+'/concrete/saved_model/y_model.pt')\n",
    "torch.save(impute_model.state_dict(), uci_path+'/concrete/saved_model/y_impute_model.pt')\n",
    "torch.save(predict_model.state_dict(), uci_path+'/concrete/saved_model/y_predict_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el modelo\n",
    "model.load_state_dict(torch.load(uci_path+'/housing/saved_model/y_model.pt'))\n",
    "impute_model.load_state_dict(torch.load(uci_path+'/housing/saved_model/y_impute_model.pt'))\n",
    "predict_model.load_state_dict(torch.load(uci_path+'/housing/saved_model/y_predict_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_y.eval()\n",
    "impute_model_y.eval()\n",
    "predict_model.eval()\n",
    "with torch.no_grad():\n",
    "    x_embd = model_y(x, train_edge_attr, train_edge_index)\n",
    "    X = impute_model_y([x_embd[edge_index[0, :int(n_row * n_col)]], x_embd[edge_index[1, :int(n_row * n_col)]]])\n",
    "    X = torch.reshape(X, [n_row, n_col])\n",
    "    pred = predict_model(X)[:, 0]\n",
    "    pred_test = pred[test_y_mask]\n",
    "    label_test = y[test_y_mask]\n",
    "    mse = F.mse_loss(pred_test, label_test)\n",
    "    test_rmse = np.sqrt(mse.item())\n",
    "    l1 = F.l1_loss(pred_test, label_test)\n",
    "    test_l1 = l1.item()\n",
    "\n",
    "val_GRAPE_y=[test_l1, test_rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 105.5803451538086 RMSE: 10.275229688615656 MAE: 7.76985502243042\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: {} RMSE: {} MAE: {}\".format(mse.item(), test_rmse,test_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43.70000076293945, 36.45000076293945, 56.13999938964844, 40.560001373291016, 53.29999923706055]\n",
      "[51.526432037353516, 42.06147766113281, 52.423709869384766, 47.10548400878906, 50.9073371887207]\n"
     ]
    }
   ],
   "source": [
    "# Vemos las primeras etiquetas real vs previstas\n",
    "print(y[test_y_mask][0:5].tolist())\n",
    "print(pred[test_y_mask][0:5].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Max Singular Value of X_init = 23.897300\n",
      "[SoftImpute] Iter 1: observed MAE=0.012911 rank=8\n",
      "[SoftImpute] Iter 2: observed MAE=0.012953 rank=8\n",
      "[SoftImpute] Iter 3: observed MAE=0.012995 rank=8\n",
      "[SoftImpute] Iter 4: observed MAE=0.013035 rank=8\n",
      "[SoftImpute] Iter 5: observed MAE=0.013074 rank=8\n",
      "[SoftImpute] Iter 6: observed MAE=0.013111 rank=8\n",
      "[SoftImpute] Iter 7: observed MAE=0.013147 rank=8\n",
      "[SoftImpute] Iter 8: observed MAE=0.013180 rank=8\n",
      "[SoftImpute] Iter 9: observed MAE=0.013212 rank=8\n",
      "[SoftImpute] Iter 10: observed MAE=0.013242 rank=8\n",
      "[SoftImpute] Iter 11: observed MAE=0.013270 rank=8\n",
      "[SoftImpute] Iter 12: observed MAE=0.013296 rank=8\n",
      "[SoftImpute] Iter 13: observed MAE=0.013321 rank=8\n",
      "[SoftImpute] Iter 14: observed MAE=0.013345 rank=8\n",
      "[SoftImpute] Iter 15: observed MAE=0.013367 rank=8\n",
      "[SoftImpute] Iter 16: observed MAE=0.013388 rank=8\n",
      "[SoftImpute] Iter 17: observed MAE=0.013408 rank=8\n",
      "[SoftImpute] Iter 18: observed MAE=0.013427 rank=8\n",
      "[SoftImpute] Iter 19: observed MAE=0.013444 rank=8\n",
      "[SoftImpute] Iter 20: observed MAE=0.013460 rank=8\n",
      "[SoftImpute] Iter 21: observed MAE=0.013476 rank=8\n",
      "[SoftImpute] Iter 22: observed MAE=0.013491 rank=8\n",
      "[SoftImpute] Iter 23: observed MAE=0.013505 rank=8\n",
      "[SoftImpute] Iter 24: observed MAE=0.013518 rank=8\n",
      "[SoftImpute] Iter 25: observed MAE=0.013531 rank=8\n",
      "[SoftImpute] Iter 26: observed MAE=0.013543 rank=8\n",
      "[SoftImpute] Iter 27: observed MAE=0.013554 rank=8\n",
      "[SoftImpute] Iter 28: observed MAE=0.013564 rank=8\n",
      "[SoftImpute] Iter 29: observed MAE=0.013573 rank=8\n",
      "[SoftImpute] Iter 30: observed MAE=0.013582 rank=8\n",
      "[SoftImpute] Iter 31: observed MAE=0.013591 rank=8\n",
      "[SoftImpute] Iter 32: observed MAE=0.013598 rank=8\n",
      "[SoftImpute] Iter 33: observed MAE=0.013606 rank=8\n",
      "[SoftImpute] Iter 34: observed MAE=0.013612 rank=8\n",
      "[SoftImpute] Iter 35: observed MAE=0.013619 rank=8\n",
      "[SoftImpute] Iter 36: observed MAE=0.013625 rank=8\n",
      "[SoftImpute] Iter 37: observed MAE=0.013630 rank=8\n",
      "[SoftImpute] Iter 38: observed MAE=0.013635 rank=8\n",
      "[SoftImpute] Iter 39: observed MAE=0.013640 rank=8\n",
      "[SoftImpute] Iter 40: observed MAE=0.013644 rank=8\n",
      "[SoftImpute] Iter 41: observed MAE=0.013648 rank=8\n",
      "[SoftImpute] Iter 42: observed MAE=0.013652 rank=8\n",
      "[SoftImpute] Iter 43: observed MAE=0.013655 rank=8\n",
      "[SoftImpute] Iter 44: observed MAE=0.013659 rank=8\n",
      "[SoftImpute] Iter 45: observed MAE=0.013662 rank=8\n",
      "[SoftImpute] Iter 46: observed MAE=0.013664 rank=8\n",
      "[SoftImpute] Iter 47: observed MAE=0.013667 rank=8\n",
      "[SoftImpute] Iter 48: observed MAE=0.013669 rank=8\n",
      "[SoftImpute] Iter 49: observed MAE=0.013672 rank=8\n",
      "[SoftImpute] Iter 50: observed MAE=0.013674 rank=8\n",
      "[SoftImpute] Iter 51: observed MAE=0.013675 rank=8\n",
      "[SoftImpute] Iter 52: observed MAE=0.013677 rank=8\n",
      "[SoftImpute] Iter 53: observed MAE=0.013679 rank=8\n",
      "[SoftImpute] Iter 54: observed MAE=0.013680 rank=8\n",
      "[SoftImpute] Iter 55: observed MAE=0.013681 rank=8\n",
      "[SoftImpute] Iter 56: observed MAE=0.013682 rank=8\n",
      "[SoftImpute] Iter 57: observed MAE=0.013684 rank=8\n",
      "[SoftImpute] Iter 58: observed MAE=0.013685 rank=8\n",
      "[SoftImpute] Iter 59: observed MAE=0.013685 rank=8\n",
      "[SoftImpute] Iter 60: observed MAE=0.013686 rank=8\n",
      "[SoftImpute] Iter 61: observed MAE=0.013687 rank=8\n",
      "[SoftImpute] Iter 62: observed MAE=0.013688 rank=8\n",
      "[SoftImpute] Iter 63: observed MAE=0.013688 rank=8\n",
      "[SoftImpute] Iter 64: observed MAE=0.013689 rank=8\n",
      "[SoftImpute] Iter 65: observed MAE=0.013690 rank=8\n",
      "[SoftImpute] Iter 66: observed MAE=0.013690 rank=8\n",
      "[SoftImpute] Iter 67: observed MAE=0.013691 rank=8\n",
      "[SoftImpute] Iter 68: observed MAE=0.013691 rank=8\n",
      "[SoftImpute] Iter 69: observed MAE=0.013691 rank=8\n",
      "[SoftImpute] Iter 70: observed MAE=0.013692 rank=8\n",
      "[SoftImpute] Iter 71: observed MAE=0.013692 rank=8\n",
      "[SoftImpute] Iter 72: observed MAE=0.013692 rank=8\n",
      "[SoftImpute] Iter 73: observed MAE=0.013693 rank=8\n",
      "[SoftImpute] Iter 74: observed MAE=0.013693 rank=8\n",
      "[SoftImpute] Iter 75: observed MAE=0.013693 rank=8\n",
      "[SoftImpute] Iter 76: observed MAE=0.013693 rank=8\n",
      "[SoftImpute] Iter 77: observed MAE=0.013693 rank=8\n",
      "[SoftImpute] Iter 78: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 79: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 80: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 81: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 82: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 83: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 84: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 85: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 86: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 87: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 88: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 89: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 90: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 91: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 92: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 93: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 94: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 95: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 96: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 97: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 98: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 99: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Iter 100: observed MAE=0.013694 rank=8\n",
      "[SoftImpute] Stopped after iteration 100 for lambda=0.477946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "y = data.y.detach().numpy()\n",
    "train_y_mask = data.train_y_mask.clone().detach()\n",
    "test_y_mask = data.test_y_mask.clone().detach()\n",
    "y_train = y[train_y_mask]\n",
    "y_test = y[test_y_mask]\n",
    "\n",
    "\n",
    "val_baseline_y=[]\n",
    "for method in ['mean', 'knn', 'mice', 'svd', 'spectral']:\n",
    "    level = best_levels[method]\n",
    "    #print(\"using best level {} for {}\".format(level,method))\n",
    "    X_filled = baseline_inpute(X_incomplete, method,level)\n",
    "    reg = LinearRegression().fit(X_filled[train_y_mask, :], y_train)\n",
    "    y_pred_test = reg.predict(X_filled[test_y_mask, :])\n",
    "    rmse = np.sqrt(np.mean((y_pred_test - y_test) ** 2))\n",
    "    mae = np.mean(np.abs(y_pred_test - y_test))\n",
    "    val_baseline_y.append([mae, rmse])\n",
    "\n",
    "# Añadimos los valores de grape\n",
    "val_baseline_y.append(val_GRAPE_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.515912</td>\n",
       "      <td>13.104135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>9.992220</td>\n",
       "      <td>12.430884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svd</th>\n",
       "      <td>10.274352</td>\n",
       "      <td>12.890592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mice</th>\n",
       "      <td>11.098787</td>\n",
       "      <td>13.665906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectral</th>\n",
       "      <td>10.738141</td>\n",
       "      <td>13.360426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grape</th>\n",
       "      <td>7.769855</td>\n",
       "      <td>10.275230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mae       rmse\n",
       "mean      10.515912  13.104135\n",
       "knn        9.992220  12.430884\n",
       "svd       10.274352  12.890592\n",
       "mice      11.098787  13.665906\n",
       "spectral  10.738141  13.360426\n",
       "grape      7.769855  10.275230"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(val_baseline_y, columns=['mae','rmse'], index=['mean', 'knn', 'svd', 'mice', 'spectral','grape'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2=df\n",
    "df2['mae']=df['mae']/df['mae']['mean']\n",
    "\n",
    "g=sns.catplot(kind=\"bar\", data=df2.T[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfecto!!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
